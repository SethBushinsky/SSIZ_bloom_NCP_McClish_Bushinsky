{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycurrents.num import mask_nonincreasing\n",
    "from pycurrents.num import interp1\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import MLD_ as m\n",
    "\n",
    "import warnings\n",
    "from math import floor, ceil\n",
    "\n",
    "from scipy import linalg  # numpy linalg plus extras\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy import stats\n",
    "from scipy import interpolate\n",
    "from scipy import constants\n",
    "import datetime as dt\n",
    "import rioxarray as rxr\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in QC'd SOCCOM snapshot\n",
    "SIZ_Floats_1=glob(\"\"\"path to May 2021 SOCCOM data snapshot files previously QC'd\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAR_extract(time_in, lat_in , lon_in):\n",
    "    ''' function to get cdr_seaice_concentration from NASA Ocean color website daily mapped L3 files. \n",
    "    https://oceancolor.gsfc.nasa.gov/l3/\n",
    "    units einstein m^-2 day^-1\n",
    "    reference :\n",
    "    Frouin, R., Ligner, D.W., and Gautier, C., 1989: A Simple analytical formula to compute clear sky total and photosynthetically available solar irradiance at the ocean surface. J. Geophys. Res., 94, 9731-9742.\n",
    "     eg. A2016356.L3m_DAY_PAR.x_par.nc\n",
    "    Uses Lat/Lon from yearly aggregate files\n",
    "    for each time in float track (\"time_in\" = datetime data array, freq not specified so can work with temporally interpolated data)\n",
    "    the closest SIC for that day is found. The mean is taken in case of two equidistance matches.\n",
    "    \n",
    "    returns array of cloud corrected par along float path\n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    #interpolate lat and lon\n",
    "    lat_in=lat_in.interpolate_na(dim=\"JULD\")\n",
    "    lon_in=lon_in.interpolate_na(dim=\"JULD\")\n",
    "    \n",
    "    PAR=np.zeros_like((time_in), dtype=float)\n",
    "    \n",
    "    for t in range(len(time_in)):\n",
    "    #find day\n",
    "        year=str(time_in[t].dt.year.values)\n",
    "        if (time_in[t].dt.dayofyear) < 10:\n",
    "            dayofyear=\"00\"+str(time_in[t].dt.dayofyear.values)\n",
    "            print(dayofyear)\n",
    "        if (time_in[t].dt.dayofyear) <100 and (time_in[t].dt.dayofyear) >= 10: \n",
    "            dayofyear=\"0\"+str(time_in[t].dt.dayofyear.values)\n",
    "        if (time_in[t].dt.dayofyear) >= 100:\n",
    "            dayofyear=str(time_in[t].dt.dayofyear.values)\n",
    "        \n",
    "        par_file= xr.open_dataset(\"/Users/shannonmcclish/Desktop/PAR_Daily/requested_files/A\"+(year)+(dayofyear)+\".L3m_DAY_PAR.x_par.nc\")\n",
    "        \n",
    "        \n",
    "        lon360=convert_180_lon_to_360(par_file.lon)\n",
    "        par_file[\"lon360\"]=xr.DataArray(data=lon360, dims=[\"lon\"])\n",
    "        lon_diff=abs(par_file.lon360-lon_in[t].values)\n",
    "        lat_diff=abs(par_file.lat-lat_in[t].values)\n",
    "        dist_weight = (lon_diff**2 + lat_diff**2)**0.5\n",
    "        \n",
    "        par_file=np.mean(par_file.where(dist_weight==dist_weight.min(), drop=True))\n",
    "        \n",
    "        \n",
    "        PAR[t]=par_file.par.values\n",
    "\n",
    "    return PAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mld(ds, rdepth, sthreshold):\n",
    "    mld_int = []\n",
    "    for k in range(len(ds.JULD.values)):\n",
    "        mld = m.calc_mld(ds.isel(JULD=k), ref_depth=rdepth, sigma_theta_crit=sthreshold)\n",
    "        mld_int.append(mld)\n",
    "    ds[\"MLD\"]= xr.DataArray(mld_int, coords=ds.coords, dims=[\"JULD\"])\n",
    "    return ds\n",
    "\n",
    "def open_SIZ_only(flt_, nlist):\n",
    "    data=xr.open_dataset(flt_)\n",
    "    for n in nlist: \n",
    "        if data[\"Float_ID\"].values == \"5903717\":\n",
    "            data=data.sel(JULD=slice(\"2016-01\", \"2019-01\"))\n",
    "        if data[\"Float_ID\"].values == \"5904180\":\n",
    "            data= data.sel(JULD=slice(\"2014-01\",\"2019-03\")) \n",
    "        if data[\"Float_ID\"].values == \"5904184\":\n",
    "            data= data.sel(JULD=slice(\"2014-01\",\"2015-07\")) \n",
    "        if data[\"Float_ID\"].values == \"5905375\":\n",
    "            data=data.sel(JULD=slice(\"2018-01\", \"2019-01\"))\n",
    "        if data[\"Float_ID\"].values == \"5905080\":\n",
    "            data=data.sel(JULD=slice(\"2017-09\", \"2020-05\"))\n",
    "    return data\n",
    "    \n",
    "def regrid(pvar, var, pgrid,coords,dims):\n",
    "    \"tranform data onto a standard grid using interp1 from pycurrents.\"\n",
    "    nprofs = var.shape[0]\n",
    "    newvar = np.ma.zeros((nprofs, pgrid.shape[0]))\n",
    "    for i in range(nprofs):\n",
    "        v = np.ma.masked_invalid(var[i])\n",
    "        p = np.ma.masked_invalid(pvar[i])\n",
    "        p = mask_nonincreasing(p[::-1])[::-1]\n",
    "        newvar[i] = interp1(p, v, pgrid,axis=1)\n",
    "    varn= xr.DataArray(newvar,coords=coords, dims=dims)\n",
    "    #mask upper 5 m \n",
    "    varn=varn.where(varn.N_LEVELS>=5)\n",
    "    return varn\n",
    "    \n",
    "def dsvars_togrid(ds_original):\n",
    "    ''''when passed a SOCCOM float dataset (opened as xarray dataset) will return datset interpolated onto a uniform depth grid\n",
    "    set by pgrid. Interpolation is only along the depth dimension using interp1 from pycurrents'''\n",
    "    ds_grid=xr.Dataset()\n",
    "    pgrid=np.arange(0,1500)\n",
    "    coordinates=ds_original.coords\n",
    "    ds_original=ds_original.interpolate_na(dim=\"JULD\", method=\"linear\", limit=2)\n",
    "    ds_grid[\"OxygenSat\"]=regrid(ds_original[\"Pressure\"],ds_original[\"OxygenSat\"],pgrid,coordinates,ds_original[\"OxygenSat\"].dims)\n",
    "    ds_grid[\"Temperature\"]=regrid(ds_original[\"Pressure\"],ds_original[\"Temperature\"],pgrid,coordinates,ds_original[\"Temperature\"].dims)\n",
    "    ds_grid[\"Salinity\"]=regrid(ds_original[\"Pressure\"],ds_original[\"Salinity\"],pgrid,coordinates,ds_original[\"Salinity\"].dims)\n",
    "    ds_grid[\"Depth\"]=regrid(ds_original[\"Pressure\"],ds_original[\"Depth\"],pgrid,coordinates,ds_original[\"Depth\"].dims)\n",
    "    if \"DIC_LIAR\" in ds_original.variables.keys():\n",
    "        ds_grid[\"DIC_LIAR\"]=regrid(ds_original[\"Pressure\"],ds_original[\"DIC_LIAR\"],pgrid,coordinates,ds_original[\"DIC_LIAR\"].dims)\n",
    "    if \"pCO2_LIAR\" in ds_original.variables.keys():\n",
    "        ds_grid[\"pCO2_LIAR\"]=regrid(ds_original[\"Pressure\"],ds_original[\"pCO2_LIAR\"],pgrid,coordinates,ds_original[\"pCO2_LIAR\"].dims)\n",
    "    ds_grid[\"Oxygen\"]=regrid(ds_original[\"Pressure\"],ds_original[\"Oxygen\"],pgrid,coordinates,ds_original[\"Oxygen\"].dims)\n",
    "    if \"pH25C\" in ds_original.variables.keys():\n",
    "        ds_grid[\"pH25C\"]=regrid(ds_original[\"Pressure\"],ds_original[\"pH25C\"],pgrid,coordinates,ds_original[\"pH25C\"].dims)\n",
    "    if \"Nitrate\" in ds_original.variables.keys():\n",
    "        ds_grid[\"Nitrate\"]=regrid(ds_original[\"Pressure\"],ds_original[\"Nitrate\"],pgrid,coordinates,ds_original[\"Nitrate\"].dims)\n",
    "    if \"Chl_a_corr\" in ds_original.variables.keys():\n",
    "        ds_grid[\"Chl_a_corr\"]=regrid(ds_original[\"Pressure\"],ds_original[\"Chl_a_corr\"],pgrid,coordinates,ds_original[\"Chl_a_corr\"].dims)\n",
    "    ds_grid['Sigma_theta']=regrid(ds_original[\"Pressure\"],ds_original[\"Sigma_theta\"],pgrid,coordinates,ds_original[\"Sigma_theta\"].dims)\n",
    "    if \"b_bp700\" in ds_original.variables.keys():\n",
    "        ds_grid['b_bp700']=regrid(ds_original[\"Pressure\"],ds_original[\"b_bp700\"],pgrid,coordinates,ds_original[\"b_bp700\"].dims)\n",
    "    if \"POC\" in ds_original.variables.keys():\n",
    "        ds_grid['POC']=regrid(ds_original[\"Pressure\"],ds_original[\"POC\"],pgrid,coordinates,ds_original[\"POC\"].dims)\n",
    "    ds_grid[\"Float_ID\"]=ds_original[\"Float_ID\"]\n",
    "    ds_grid[\"Lat\"]=ds_original[\"Lat\"]\n",
    "    ds_grid[\"Lat_QF\"]=ds_original[\"Lat_QF\"]\n",
    "    ds_grid[\"Lon\"]=ds_original[\"Lon\"]\n",
    "    ds_grid[\"MLD\"]=ds_original[\"MLD\"]\n",
    "    ds_grid=ds_grid.rename({'N_LEVELS':'Pressure'})\n",
    "    return ds_grid\n",
    " \n",
    "def prof_data_2(ds, interp_na=False):\n",
    "    \"\"\"\n",
    "    resamples to daily timestep with linerar interpolation where first and last day match date of \n",
    "    profile, timestep is set to zero\n",
    "    \"\"\"\n",
    "    bin1=ds.groupby(ds.JULD.dt.floor(freq='1D')).mean()\n",
    "    if interp_na==False:\n",
    "        binnedint=bin1.resample(floor=\"D\").interpolate()\n",
    "    else:\n",
    "        binnedint==bin1.resample(floor=\"D\").interpolate_na()\n",
    "    ds1=binnedint.rename_dims({\"floor\":\"JULD\"})\n",
    "    ds1=binnedint.rename({'floor':'JULD'})\n",
    "    \n",
    "    return ds1\n",
    "    \n",
    "\n",
    "    return da_match\n",
    "def convert_360_lon_to_180(lons):\n",
    "    \"\"\" Converts any-dimension array of longitudes from 0 to 360 to longitudes from -180 to 180.\n",
    "    \"\"\"\n",
    "    lons = np.array(lons)\n",
    "    outside_range = lons > 180\n",
    "    lons[outside_range] = lons[outside_range] - 360\n",
    "    return lons\n",
    "\n",
    "def convert_180_lon_to_360(lons):\n",
    "    \"\"\" Converts any-dimension array of longitudes from -180 to 180 t0 0 to 360 to longitude.\n",
    "    \"\"\"\n",
    "    lons = np.array(lons)\n",
    "    outside_range = lons < 0\n",
    "    lons[outside_range] = lons[outside_range] + 360\n",
    "    return lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_solar_radiation(lat_in, lon_in, time_in):\n",
    "    \"\"\"returns Mean surface downward short-wave radiation flux [Wm-2]\n",
    "    This parameter is the amount of solar radiation (also known as shortwave radiation) that \n",
    "    reaches a horizontal plane at the surface of the Earth.\n",
    "    This parameter is a mean over a particular time period (the processing period) which depends \n",
    "    on the data extracted. For the monthly averaged reanalysis and the monthly averaged ensemble members, \n",
    "    the processing period is the complete, whole month.\"\"\"\n",
    "    #time_in=time_in.values.astype(str)[0:10]\n",
    "    #interpolate lat and lon\n",
    "    lat_in=lat_in.interpolate_na(dim=\"JULD\")\n",
    "    lon_in=lon_in.interpolate_na(dim=\"JULD\")\n",
    "    lon_in=convert_360_lon_to_180(lon_in)\n",
    "    \n",
    "    rad=xr.open_dataset(\"/Users/shannonmcclish/Desktop/argo_data/Sea_Ice_Project/mean_solar_rad_down_monthly.nc\")\n",
    "    rad_noexpver=rad.sel(expver=1)\n",
    "    MSD=np.zeros_like((time_in), dtype=float)\n",
    "    for t in range(len(time_in)):\n",
    "        \n",
    "        lat_in_t=round(lat_in[t].values*4)/4\n",
    "        lon_in_t=round(lon_in[t]*4)/4\n",
    "        if np.isnan(lat_in_t)==True or np.isnan(lon_in_t)==True:\n",
    "            MSD[t]=\"Nan\"\n",
    "        elif lat_in_t > -52.0:\n",
    "            print(lat_in_t)\n",
    "            MSD[t]=\"Nan\"\n",
    "        else:\n",
    "            \n",
    "            msd=rad_noexpver.msdwswrf.sel(latitude=lat_in_t, longitude=lon_in_t)\n",
    "            msd=msd.interpolate_na(dim=\"time\")\n",
    "            msd=msd.resample(time=\"D\").interpolate()\n",
    "            time_in_t=time_in[t].values.astype(str)[0:10]\n",
    "\n",
    "            MSD[t]=msd.sel(time=time_in_t)\n",
    "    \n",
    "    return MSD\n",
    "def SIC_extract(time_in, lat_in , lon_in):\n",
    "    ''' function to get cdr_seaice_concentration from NOAA/NSDIC daily files. Uses Lat/Lon from yearly aggregate files\n",
    "    for each time in float track (\"time_in\" = datetime data array, freq not specified so can work with temporally interpolated data)\n",
    "    the closest SIC for that day is found. The mean is taken in case of two equidistance matches.\n",
    "    The sea ice conc is set to Nan where 2.53 (coast), 2.54 (land), 2.55 (missing data)\n",
    "    \n",
    "    returns array of sea ice conc along float path\n",
    "    \n",
    "    '''\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "    #interpolate lat and lon\n",
    "    lat_in=lat_in.interpolate_na(dim=\"JULD\")\n",
    "    lon_in=lon_in.interpolate_na(dim=\"JULD\")\n",
    "    \n",
    "    SIC=np.zeros_like((time_in), dtype=float)\n",
    "    for t in range(len(time_in)):\n",
    "    #find day\n",
    "        if time_in[t].dt.year > 2008:\n",
    "            year=str(time_in[t].dt.year.values)\n",
    "        if ((time_in[t].dt.month)) < 10: \n",
    "            month=\"0\"+str(time_in[t].dt.month.values)\n",
    "\n",
    "\n",
    "        else: month=str(time_in[t].dt.month.values)\n",
    "\n",
    "\n",
    "\n",
    "        if ((time_in[t].dt.day)) < 10: \n",
    "            day=\"0\"+str(time_in[t].dt.day.values)\n",
    "\n",
    "\n",
    "        else: day=str(time_in[t].dt.day.values)\n",
    "        if time_in[t].dt.year < 2021:\n",
    "            cdr_file = xr.open_dataset(\"/Users/shannonmcclish/Desktop/argo_data/Sea_Ice_Project/SeaIce/seaice_conc_daily_sh_\"+year+month+day+'_f17_v04r00.nc')\n",
    "            cdr_file_agg=xr.open_dataset(\"/Users/shannonmcclish/Desktop/argo_data/Sea_Ice_Project/Data/seaice_conc_daily_sh_\"+year+'_v04r00.nc')\n",
    "        else:\n",
    "            cdr_file = xr.open_dataset(\"/Users/shannonmcclish/Desktop/argo_data/Sea_Ice_Project/nrt/daily/seaice_conc_daily_icdr_sh_\"+year+month+day+'_f18_v02r00.nc')\n",
    "            cdr_file_agg=xr.open_dataset(\"/Users/shannonmcclish/Desktop/argo_data/Sea_Ice_Project/nrt/agg/G02202-cdr-ancillary-sh.nc\")\n",
    "\n",
    "        cdr_file[\"latitude\"]=cdr_file_agg.latitude\n",
    "        cdr_file[\"longitude\"]=cdr_file_agg.longitude\n",
    "        lon360=convert_180_lon_to_360(cdr_file.longitude)\n",
    "        cdr_file[\"lon360\"]=xr.DataArray(data=lon360, dims=[\"y\",\"x\"])\n",
    "        lon_diff=abs(cdr_file.lon360-lon_in[t].values)\n",
    "        lat_diff=abs(cdr_file.latitude-lat_in[t].values)\n",
    "        dist_weight = (lon_diff**2 + lat_diff**2)**0.5\n",
    "\n",
    "        cdr_file=np.mean(cdr_file.where(dist_weight==dist_weight.min(), drop=True))\n",
    "\n",
    "\n",
    "        #cdr_file=cdr_file.where(cdr_file.cdr_seaice_conc < 2.51)\n",
    "        if cdr_file.cdr_seaice_conc.any() == 2.52:\n",
    "            cdr_file.cdr_seaice_conc = NaN # lake mask\n",
    "            print(\"lake\")\n",
    "        if cdr_file.cdr_seaice_conc.any() == 2.53:\n",
    "            cdr_file.cdr_seaice_conc = NaN # coast mask\n",
    "            print(\"coast\")\n",
    "        if cdr_file.cdr_seaice_conc.any() == 2.54:\n",
    "            cdr_file.cdr_seaice_conc = NaN # land mask\n",
    "            print(\"land\")\n",
    "        if cdr_file.cdr_seaice_conc.any() == 2.55:\n",
    "            cdr_file.cdr_seaice_conc = NaN # land mask\n",
    "            print(\"missing data\")\n",
    "\n",
    "\n",
    "        SIC[t]=cdr_file.cdr_seaice_conc.values\n",
    "\n",
    "    return SIC\n",
    "\n",
    "def mldmean(ds, Snorm=False):\n",
    "    mldsliceN=np.ma.zeros((len(ds.JULD),1))\n",
    "    mldsliceC=np.ma.zeros((len(ds.JULD),1))\n",
    "    mldsliceO=np.ma.zeros((len(ds.JULD),1))\n",
    "    mldsliceOSat=np.ma.zeros((len(ds.JULD),1))\n",
    "    mldsliceS=np.ma.zeros((len(ds.JULD),1))\n",
    "    mldsliceSig_theta=np.ma.zeros((len(ds.JULD),1))\n",
    "    mldsliceT=np.ma.zeros((len(ds.JULD),1))\n",
    "    mldsliceChl_a=np.ma.zeros((len(ds.JULD),1))\n",
    "    mldslicebbp=np.ma.zeros((len(ds.JULD),1))\n",
    "    mldsliceCp=np.ma.zeros((len(ds.JULD),1))\n",
    "    mld_no_nan=ds.MLD.interpolate_na(dim=\"JULD\", fill_value=\"extrapolate\")\n",
    "    if Snorm == True:\n",
    "        mldsliceNSnorm=np.ma.zeros((len(ds.JULD),1))\n",
    "       \n",
    "    #mld_no_nan=ds.MLD.interpolate_na(dim=\"JULD\", fill_value=\"extrapolate\")\n",
    "    for t in range(len(ds.JULD)):\n",
    "        mldo=mld_no_nan.isel(JULD=t)\n",
    "        \n",
    "        mldsliceN[t]=ds.Nitrate[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "        \n",
    "        if Snorm == True:\n",
    "            mldsliceNSnorm[t]=ds.Snorm_Nitrate[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "            \n",
    "        if \"DIC_LIAR\" in ds.variables.keys():\n",
    "            mldsliceC[t]=ds.DIC_LIAR[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "        mldsliceO[t]=ds.Oxygen[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "        mldsliceOSat[t]=ds.OxygenSat[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "        mldsliceS[t]=ds.Salinity[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "        mldsliceSig_theta[t]=ds.Sigma_theta[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "        mldsliceT[t]=ds.Temperature[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "        mldsliceChl_a[t]=ds.Chl_a_corr[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "        mldslicebbp[t]=ds.b_bp700[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "        mldsliceCp[t]=ds.C_phyto[t,:].isel(Pressure=slice(0,ceil(mldo.values)+1)).mean(dim=\"Pressure\")\n",
    "    ds[\"ML_N\"]= xr.DataArray(mldsliceN, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    if Snorm == True:\n",
    "            ds[\"ML_NSnorm\"]= xr.DataArray(mldsliceNSnorm, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "            \n",
    "    ds[\"ML_C\"]= xr.DataArray(mldsliceC, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    ds[\"ML_O\"]= xr.DataArray(mldsliceO, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    ds[\"ML_OSat\"]= xr.DataArray(mldsliceOSat, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    ds[\"ML_S\"]= xr.DataArray(mldsliceS, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    ds[\"ML_Sig_theta\"]= xr.DataArray(mldsliceSig_theta, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    ds[\"ML_T\"]= xr.DataArray(mldsliceT, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    ds[\"ML_Chl_a\"]= xr.DataArray(mldsliceChl_a, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    ds[\"ML_b_bp700\"]= xr.DataArray(mldslicebbp, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    ds[\"ML_C_phyto\"]= xr.DataArray(mldsliceCp, dims=[\"JULD\", \"ML\"], coords=dict(JULD=(ds.JULD)))\n",
    "    \n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cphyto(bbp):\n",
    "    \"\"\"returns C-phyto [mg/m3] from float bbp (Graff et al 2015). \n",
    "    For each Cphyto profile subtract the mean estimated concentration between 900 m and 1500 m \n",
    "    from the entire vertical profile, in order to make sure that phytoplankton carbon asymptotes \n",
    "    towards zero at depth following Artega et al 2020 (who did 900-2000m, but I did 900-1500 because myQC files\n",
    "    only include to 1500m)\"\"\"\n",
    "    #BBP700 to BBP470\n",
    "    bbp470=bbp*(470/700)**-1  # -1 from Morel and Morent as in Areteaga et al 2022\n",
    "    #C_phyto from Graff 2015\n",
    "    C_phyto = 12128 * bbp470 + .59\n",
    "    background=C_phyto.sel(Pressure=slice(900,1500)).mean()\n",
    "    C_phyto=C_phyto-background\n",
    "    return C_phyto\n",
    "\n",
    "\n",
    "\n",
    "def bloom_metrics_daily (Chl_a, Cp):\n",
    "    \"\"\"find Growth initiation based on chl_a and Cp individually \"\"\"\n",
    "    #find Chl minimum before Chl maximum\n",
    "    \"\"\"Chl_a_min=Chl_a.min()\"\"\"\n",
    "    Chl_a_maxt=Chl_a.where(Chl_a==Chl_a.max(), drop=True).JULD \n",
    "    #find timing of min in CHl occuring prior to apex\n",
    "    Chl_a_beforemax=Chl_a.where(Chl_a.JULD< Chl_a_maxt.values, drop=True)\n",
    "    Chl_a_mint=Chl_a_beforemax.where(Chl_a_beforemax==Chl_a_beforemax.min(), drop=True).JULD\n",
    "    \n",
    "    #find delta chl per day- center difference\n",
    "    Chl_a_dt=Chl_a.diff(dim=\"JULD\")\n",
    "    time_center=Chl_a_dt.JULD.values - np.timedelta64(12, 'h')\n",
    "    Chl_a_dt=Chl_a_dt.assign_coords({\"JULD\": time_center})\n",
    "    #find where rate of change is positive\n",
    "    Chl_a_dt=Chl_a_dt.where(Chl_a_dt>0, drop=True) \n",
    "    #median of positive period\n",
    "    Chl_a_dt_median=Chl_a_dt.median() \n",
    "    #find where rate of change is positive and exceeds median d/dt threshold\n",
    "    Chl_a_exceeds_median=Chl_a_dt.where(Chl_a_dt > Chl_a_dt_median, drop=True).JULD\n",
    "    #find first occurence of threshold exceedance that follows min CHl/BBP (GI)\n",
    "    GI_Chl_a=Chl_a_exceeds_median.where(Chl_a_exceeds_median.JULD > Chl_a_mint[0].values, drop=True)\n",
    "    \n",
    "    #choose first if repeat values\n",
    "    if len(GI_Chl_a) > 1:\n",
    "        GI_Chl_a=GI_Chl_a[0]\n",
    "       \n",
    "    #repeat with Cp\n",
    "    Cp_min=Cp.min()\n",
    "    Cp_maxt=Cp.where(Cp==Cp.max(), drop=True).JULD \n",
    "    Cp_beforemax=Cp.where(Cp.JULD< Cp_maxt.values, drop=True)\n",
    "    Cp_mint=Cp_beforemax.where(Cp_beforemax==Cp_beforemax.min(), drop=True)[0].JULD\n",
    "    Cp_dt=(Cp.diff(dim=\"JULD\"))\n",
    "    time_center=Cp_dt.JULD.values - np.timedelta64(12, 'h')\n",
    "    Cp_dt=Cp_dt.assign_coords({\"JULD\": time_center})\n",
    "    Cp_dt=Cp_dt.where(Cp_dt>0, drop=True) \n",
    "    \n",
    "    Cp_dt_median=Cp_dt.median() \n",
    "    Cp_exceeds_median=Cp_dt.where(Cp_dt > Cp_dt_median, drop=True).JULD\n",
    "    GI_Cp=Cp_exceeds_median.where(Cp_exceeds_median.JULD > Cp_mint.values, drop=True)\n",
    "    \n",
    "    Cp_GI=Cp.where(Cp.JULD>GI_Cp[0].values, drop=True) \n",
    "    if len(GI_Cp) > 1:\n",
    "        GI_Cp=GI_Cp[0]\n",
    "    \n",
    "    return(GI_Chl_a, GI_Cp)\n",
    "\"\"\"Find time before spring min/max where values become greater than two lowest\n",
    "or highest winter value mean +/-'set_thresh_values' ex. Finds time when mean ML \n",
    "Nitrate decreases from winter mean +/- .2 umol/kg and continues decreasing to spring minimum\"\"\"\n",
    "def thresholds2(ds,v, set_thresh_values, tstart,  max_=True):\n",
    "    \n",
    "    if max_ == True: \n",
    "        min_t=ds[v].where(ds[v]==ds[v].min(),drop=True)[0].JULD.values\n",
    "        transition=ds[v].where(ds[v].JULD<min_t, drop=True)\n",
    "        sorter=ds[v].sel(JULD=str(tstart)).where(ds[v].sel(JULD=str(tstart))<ds[v].sel(JULD=str(tstart)).max(), drop=True)\n",
    "        maxtwo=sorter.max()\n",
    "        twomean=(ds[v].sel(JULD=str(tstart)).max()+ maxtwo)/2\n",
    "        \"\"\"threshold exceedance is calculated from mean of 2 highest winter values\"\"\"\n",
    "        set_threshold2=transition.where(transition>= (twomean-set_thresh_values), drop=True)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        max_t=ds[v].where(ds[v]==ds[v].max(),drop=True)[0].JULD.values\n",
    "        min_t=ds[v].where(ds[v]==ds[v].min(),drop=True)[0].JULD.values\n",
    "        #5905080 has highest O2 first day of July 2018 before ice cover-explicitly select spring O2 max-not neccessary step for other flt. timeseries\n",
    "        if ds.Float_ID == \"5905080\" and tstart == 2018:\n",
    "            print (\"got here\")\n",
    "            max_t=ds[v].where(ds[v].where(ds[v].JULD>min_t, drop=True) == (ds[v].where(ds[v].JULD>min_t, drop=True)).max(), drop=True)[0].JULD.values\n",
    "            print(max_t)\n",
    "        transition=ds[v].where(ds[v].JULD<max_t, drop=True)\n",
    "        sorter=ds[v].sel(JULD=str(tstart)).where(ds[v].sel(JULD=str(tstart))>ds[v].sel(JULD=str(tstart)).min(), drop=True)\n",
    "        mintwo=sorter.min()\n",
    "        twomean=(ds[v].sel(JULD=str(tstart)).min()+ mintwo)/2\n",
    "        \n",
    "        set_threshold2=transition.where(transition<=(twomean+set_thresh_values), drop=True)\n",
    "\n",
    "    \n",
    "    return set_threshold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE must apply the QC to flt data (using May 2021 SOCCOM snapshot) prior to analysis\n",
    "def phenology_DF_daily(region, t_start, t_end, t_slice, t_slice2):\n",
    "    \"t_start and t_end are time period start and end as intgers, tslice is time slice or year\"\n",
    "    DF = pd.DataFrame()\n",
    "    for i in range(len(region)):\n",
    "        ds1=xr.open_dataset(region[i])\n",
    "        ds1=ds1.sel(JULD=t_slice)\n",
    "        \n",
    "        #6         \n",
    "        if ds1.Float_ID in [\"5904180\", \"5904397\", \"5904467\", \"5904468\", \"5904471\", \"5904472\"] and t_start == 2015:\n",
    "            print(\"2015 flt\")\n",
    "        #6\n",
    "        elif ds1.Float_ID in [\"5904180\", \"5904397\", \"5904467\", \"5904468\", \"5904471\", \"5904472\"] and t_start == 2016:\n",
    "            print(\"2016 flt\")\n",
    "        #11\n",
    "        elif ds1.Float_ID in [\"5904397\", \"5904467\", \"5904468\", \"5904471\", \"5904472\", \"5904859\", \"5905075\", \"5905077\", \"5905078\", \"5905100\", \"5905102\"] and t_start == 2017:\n",
    "            print(\"2017 flt\")\n",
    "        #14\n",
    "        elif ds1.Float_ID in [\"5904397\",\"5904468\", \"5904471\", \"5904472\", \"5904855\",\"5905075\", \"5905080\", \"5905100\", \"5905374\", \"5905636\",\"5905635\", \"5905637\",\"5905638\", \"5905639\"] and t_start ==2018:\n",
    "            print(\"2018 flt\")\n",
    "        #17\n",
    "        elif ds1.Float_ID in [\"5904855\", \"5905080\", \"5905636\",\"5905635\", \"5905637\",\"5905638\", \"5905991\", \"5905992\", \"5905994\", \"5905995\", \"5905997\", \"5906000\", \"5906005\", \"5906006\", \"5906033\", \"5906034\"] and t_start== 2019:\n",
    "            print(\"2019 flt\")\n",
    "        #11\n",
    "        elif ds1.Float_ID in [\"5905636\", \"5905637\",\"5905991\", \"5905992\", \"5905994\", \"5905995\", \"5905997\", \"5905998\",\"5906005\",\"5906033\", \"5906034\"] and t_start == 2020:\n",
    "            print (\"2020 flt\")\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "       \n",
    "        #calculate MLD\n",
    "        ds_mld=calc_mld(ds1,10,.03)\n",
    "        #Uniform pressure grid interpolation\n",
    "        ds1=dsvars_togrid(ds_mld)\n",
    "        \n",
    "        ds1[\"C_phyto\"]=Cphyto(ds1.b_bp700)\n",
    "        ds1[\"Snorm_Nitrate\"]=ds1.Nitrate*(ds1.Salinity/35) #see Papadimitriou et al 2012 or 2021 for details        \n",
    "        #mixed layer means\n",
    "        ds1=mldmean(ds1, Snorm=True)\n",
    "        #find when float senes ice cover\n",
    "        flt_SI=ds1.Lat_QF.where(ds1.Lat_QF==b'4',drop=True)\n",
    "        #fill in missing upper ocean under ice values with ML mean values, only need to do this for varibles\n",
    "        #that will be integrated down to 200m for analysis\n",
    "        ds2=ds1.sel(Pressure=slice(0,45))\n",
    "        ds2=ds2.assign_coords({\"Pressure\":ds2.Pressure})\n",
    "        ds3=ds1.sel(Pressure=slice(45,201))\n",
    "        ds3=ds3.assign_coords({\"Pressure\":ds3.Pressure+45})\n",
    "        ds2[\"Snorm_Nitrate\"]=ds2.Snorm_Nitrate.fillna(ds1.ML_NSnorm)\n",
    "        ds2[\"Sigma_theta\"]=ds2.Sigma_theta.fillna(ds1.ML_Sig_theta)\n",
    "        ds2[\"Chl_a_corr\"]=ds2.Chl_a_corr.fillna(ds1.ML_Chl_a)\n",
    "        ds2[\"C_phyto\"]=ds2.C_phyto.fillna(ds1.ML_C_phyto)\n",
    "        ds_filled=xr.concat(([ds2, ds3]), dim=\"Pressure\")\n",
    "        ds_filled=ds_filled.where(ds_filled.Snorm_Nitrate.count(dim=\"Pressure\")>=199, drop=True)\n",
    "        \n",
    "        if np.array(t_start) in ds1.JULD.dt.year.values and np.array(t_end) in ds1.JULD.dt.year.values: \n",
    "            with warnings.catch_warnings():\n",
    "                # this will suppress all warnings in this block  \n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                ds1[\"SIC\"]=xr.DataArray(data=SIC_extract(ds1.JULD, ds1.Lat, ds1.Lon), dims=\"JULD\", coords={\"JULD\": ds1.JULD})\n",
    "                ds1[\"RAD\"]=xr.DataArray(data=match_solar_radiation(ds1.Lat, ds1.Lon, ds1.JULD), dims=\"JULD\", coords={\"JULD\": ds1.JULD})   \n",
    "        else: \n",
    "            print(\"Time period not captured by float\")\n",
    "            continue\n",
    "        \n",
    "        #double check SIC max>80% and nitrate is not missing more than 1 profiles\n",
    "        if ds1.SIC.max().values <.8:\n",
    "            print(\"SIC max < 80\")\n",
    "            continue\n",
    "        if ds1.ML_N.dropna(dim=\"JULD\").count() < (ds1.JULD.count()-1) or ds1.ML_C_phyto.dropna(dim=\"JULD\").count() < (ds1.JULD.count()-1):\n",
    "            print(\"missing N or Cphyto\")\n",
    "            continue\n",
    "        if ds1.ML_O.dropna(dim=\"JULD\").count() < (ds1.JULD.count()-1) or ds1.ML_S.dropna(dim=\"JULD\").count() < (ds1.JULD.count()-1):\n",
    "            print(\"missing O or S\")\n",
    "            continue\n",
    "        if ds1.ML_Chl_a.dropna(dim=\"JULD\").count() < (ds1.JULD.count()-1): \n",
    "            print(\"missing Chl\")\n",
    "            continue\n",
    "        \n",
    "        #daily resample-select July 1 to end of March\n",
    "        float_ID=ds1.Float_ID\n",
    "        ds1=ds1.drop([\"Float_ID\", \"Lat_QF\"])\n",
    "        \n",
    "        ds1=prof_data_2(ds1)\n",
    "        ds1=ds1.sel(JULD=t_slice2)\n",
    "        ds_filled=prof_data_2(ds_filled)\n",
    "        ds_filled=ds_filled.sel(JULD=t_slice2)\n",
    "        \n",
    "        \n",
    "        ########################\n",
    "        mldmax= ds1.MLD.rolling(JULD=30, center=True).mean().max().values\n",
    "        #integrate nitrate to winter MLD max\n",
    "        N_MLD_unsmooth=ds_filled.Snorm_Nitrate.sel(Pressure=slice(5,mldmax+1))\n",
    "        N_MLD_umolm3_unsmooth=N_MLD_unsmooth*(ds_filled.Sigma_theta.sel(Pressure=slice(5,mldmax+1))+1000)\n",
    "        N_MLD_int_unsmooth=N_MLD_umolm3_unsmooth.sum(dim=\"Pressure\")\n",
    "        #smooth depth integrated nitrate, ML means (ds1) with 30 day running mean\n",
    "        N_MLD_int_smooth=N_MLD_int_unsmooth.rolling(JULD=30, center=True, min_periods=1).mean()\n",
    "        dNdt=N_MLD_int_smooth.diff(dim=\"JULD\")\n",
    "        ds1=ds1.rolling(JULD=30, center=True, min_periods=1).mean()\n",
    "        ds1[\"Float_ID\"]=float_ID\n",
    "        \n",
    "        \n",
    "        #calculate Growth Initiation \n",
    "        GI,   GI_C =bloom_metrics_daily(ds1.ML_Chl_a.interpolate_na(dim=\"JULD\"), ds1.ML_C_phyto.interpolate_na(dim=\"JULD\"))\n",
    "        #create output file\n",
    "        \n",
    "        #############\n",
    "        output_ds=xr.Dataset(coords={\"Float_ID\":float_ID})\n",
    "        output_ds[\"Float_ID\"]=float_ID.values\n",
    "        output_ds[\"Year\"]=ds1.JULD[0].dt.year.values\n",
    "        output_ds[\"SIC15_duration\"]=len(ds1.SIC.where(ds1.SIC<.15,drop=True))\n",
    "        output_ds[\"last_flt_detects_ice_prof\"]=flt_SI.where(flt_SI==b'4',drop=True)[-1].JULD.dt.dayofyear.values            \n",
    "        \n",
    "        set_O_thresh_redfield=.2*(154/17) #Hedges et al 2002 \n",
    "        flt_ratio=(ds1.ML_O.isel(JULD=slice(0,30)).mean()/ds1.ML_N.isel(JULD=slice(0,30)).mean()).values\n",
    "        #set_O_thresh_flt=.2*flt_ratio\n",
    "        mldmax_t=ds1.MLD.where(ds1.MLD==ds1.MLD.max().values, drop=True).JULD[-1]\n",
    "        NS_exceeds_set_thresh=thresholds2(ds1, \"ML_NSnorm\",.2, t_start, max_=True)\n",
    "        S_set_thresh15=thresholds2(ds1, \"ML_S\",.015,  t_start, max_=True)\n",
    "        SIC2 =thresholds2(ds1, \"SIC\", .025,  t_start,max_=True)\n",
    "        O_exceeds_set_thresh=thresholds2(ds1, \"ML_O\", set_O_thresh_redfield, t_start, max_=False)\n",
    "        chl_exceeds_set_thresh=thresholds2(ds1, \"ML_Chl_a\", .035  ,t_start,max_=False) #.035 from .2 umol/kg nitrate and μg chl:μmol N from Moreau et al 2020\n",
    "        \n",
    "        SIC_last_max=ds1.SIC.where(ds1.SIC==ds1.SIC.max(), drop=True)[-1].JULD\n",
    "        SIC_after_max=ds1.SIC.where(ds1.SIC.JULD>SIC_last_max.values, drop=True)\n",
    "        SIC_min_after_max=SIC_after_max.where(SIC_after_max==ds1.SIC.min(), drop=True)[0].JULD\n",
    "        SIC_min=ds1.SIC.where(ds1.SIC==ds1.SIC.min(), drop=True)[0].JULD\n",
    "        SIC_before_min=ds1.SIC.where(ds1.SIC.JULD<SIC_min.values)\n",
    "        \n",
    "        \n",
    "        N_min_date_smooth=N_MLD_int_smooth.sel(JULD=str(t_end)).where(N_MLD_int_smooth.sel(JULD=str(t_end))==N_MLD_int_smooth.sel(JULD=str(t_end)).min().values, drop=True)[0].JULD.values\n",
    "        N_max_date_smooth=N_MLD_int_smooth.sel(JULD=str(t_start)).where(N_MLD_int_smooth.sel(JULD=str(t_start))==N_MLD_int_smooth.sel(JULD=str(t_start)).max().values, drop=True)[-1].JULD.values\n",
    "        Nint_max_aftermldmax_smooth=N_MLD_int_smooth.sel(JULD=str(t_start)).where(N_MLD_int_smooth.sel(JULD=slice(mldmax_t.values, ds1.JULD[-1]))==N_MLD_int_smooth.sel(JULD=slice(mldmax_t.values, ds1.JULD[-1])).max().values, drop=True).JULD[-1]\n",
    "        \n",
    "        output_ds[\"SIC_max\"]=ds1.SIC.max().values\n",
    "        output_ds[\"MLCp_at_GI_C_mgm3\"]=ds1.ML_C_phyto.interp(JULD=GI_C.values)[0].values\n",
    "        output_ds[\"MLChla_at_GI_mgm3\"]=ds1.ML_Chl_a.interp(JULD=GI.values)[0].values\n",
    "        output_ds[\"MLCp_at_GI_mgm3\"]=ds1.ML_C_phyto.interp(JULD=GI.values)[0].values\n",
    "        output_ds[\"MLChla_at_GI_C_mgm3\"]=ds1.ML_Chl_a.interp(JULD=GI_C.values)[0].values\n",
    "        \n",
    "        output_ds[\"ML_40\"]=len(ds1.MLD.where(ds1.MLD<40, drop=True))\n",
    "        output_ds[\"S_set_thresh15\"]=S_set_thresh15[-1].JULD.dt.dayofyear.values\n",
    "        if float_ID==\"5905998\":\n",
    "            SIC_025=SIC_after_max.where(SIC_after_max<(ds1.SIC.max().values-.025), drop=True)[0].JULD\n",
    "            output_ds[\"SIC_thresh\"]=SIC_025.dt.dayofyear.values\n",
    "        else:\n",
    "            SIC_025=SIC2[-1].JULD\n",
    "            output_ds[\"SIC_thresh\"]=SIC_025.dt.dayofyear.values\n",
    "\n",
    "        output_ds[\"Lat\"]=ds1.Lat.mean().values\n",
    "        Kd490_chl=(0.0166 + 0.0773* ds1.ML_Chl_a**0.6715) #Kd490 from Morel et al, 2007\n",
    "        #Kd490 to KdPAR from (Morel et al., 2007 eq. 4a and 4b)\n",
    "        KdPAR_chl=np.zeros(len(Kd490_chl))\n",
    "        for i in range(len(ds1.JULD)):\n",
    "            if Kd490_chl[i]**-1>ds1.MLD[i]:\n",
    "                KdPAR_chl[i]=0.0864 + 0.884 * Kd490_chl[i] -0.00137*Kd490_chl[i]**-1\n",
    "            else:\n",
    "                KdPAR_chl[i]=0.0665 + 0.874 * Kd490_chl[i] - 0.00121*Kd490_chl[i]**-1\n",
    "                 \n",
    "        # RAD to PAR from Britton and Dodd 1976; 2.3*Irradiance [W/m2] = umol/m2/s *10**-6*86400 = [mol/m2/day]\n",
    "        #similar to Gupta 2020 (assume ~40% RAD is PAR)\n",
    "        ds1[\"ML_median_total\"]=(((2.3*ds1.RAD)*10**-6)*86400)*np.exp(-KdPAR_chl*ds1.MLD/2)\n",
    "        \n",
    "        output_ds[\"GI_C\"]=GI_C.dt.dayofyear.values\n",
    "        output_ds[\"GI\"]=GI.dt.dayofyear.values\n",
    "\n",
    "        output_ds[\"bloom_duration_GI\"]=ds1.ML_Chl_a.where(ds1.ML_Chl_a==ds1.ML_Chl_a.max(), drop=True).JULD-GI\n",
    "        output_ds[\"bloom_duration_Chl_thresh\"]=ds1.ML_Chl_a.where(ds1.ML_Chl_a==ds1.ML_Chl_a.max(), drop=True).JULD-chl_exceeds_set_thresh[-1].JULD\n",
    "\n",
    "        output_ds[\"NO3_thresh\"]=NS_exceeds_set_thresh[-1].JULD.dt.dayofyear.values\n",
    "        output_ds[\"Chl_thresh\"]=chl_exceeds_set_thresh[-1].JULD.dt.dayofyear.values\n",
    "        if output_ds.Chl_thresh<200:\n",
    "            output_ds[\"Chl_thresh\"]=chl_exceeds_set_thresh[-1].JULD.dt.dayofyear.values+365\n",
    "            \n",
    "        output_ds[\"O2_thresh\"]=O_exceeds_set_thresh[-1].JULD.dt.dayofyear.values\n",
    "        \n",
    "        if NS_exceeds_set_thresh[-1].JULD<mldmax_t.values:\n",
    "            print(float_ID.values, \"Nitrate threshold before MLD Maximum \\n \\n \\n\")\n",
    "            output_ds[\"NCP\"]=(dNdt.sel(JULD=slice(N_max_date_smooth,N_min_date_smooth))*(-106/16)*(10**-6)).sum().values\n",
    "            output_ds[\"fractionNCP_atSIC0\"]=((dNdt.sel(JULD=slice(N_max_date_smooth,N_min_date_smooth))*(-106/16)*(10**-6)).cumsum()/output_ds.NCP.values).where(ds1.JULD==SIC_min_after_max.values, drop=True)[0]\n",
    "            ds1[\"median_light\"]=ds1.ML_median_total*((1-ds1.SIC))+(ds1.SIC*ds1.ML_median_total*.09)\n",
    "            output_ds[\"GP\"]=N_max_date_smooth-N_min_date_smooth\n",
    "            output_ds[\"Nint_max_date\"]=N_max_date_smooth\n",
    "            output_ds[\"GP_light\"]=ds1.median_light.sel(JULD=slice(N_max_date_smooth, N_min_date_smooth)).sum()\n",
    "        else:\n",
    "            output_ds[\"NCP\"]=(dNdt.sel(JULD=slice(Nint_max_aftermldmax_smooth,N_min_date_smooth))*(-106/16)*(10**-6)).sum().values\n",
    "            ds1[\"median_light\"]=ds1.ML_median_total*((1-ds1.SIC))+(ds1.SIC*ds1.ML_median_total*.09)\n",
    "            if N_min_date_smooth<SIC_min_after_max.values:\n",
    "                output_ds[\"fractionNCP_atSIC0\"]=1\n",
    "            else:\n",
    "                output_ds[\"fractionNCP_atSIC0\"]=((dNdt.sel(JULD=slice(Nint_max_aftermldmax_smooth,N_min_date_smooth))*(-106/16)*(10**-6)).cumsum()/output_ds.NCP.values).where(dNdt.JULD==SIC_min_after_max.values, drop=True)[0]\n",
    "            output_ds[\"GP_light\"]=ds1.median_light.sel(JULD=slice(Nint_max_aftermldmax_smooth, N_min_date_smooth)).sum()\n",
    "            output_ds[\"GP\"]=Nint_max_aftermldmax_smooth-N_min_date_smooth\n",
    "            output_ds[\"Nint_max_date\"]=Nint_max_aftermldmax_smooth\n",
    "            \n",
    "        output_ds[\"Nint_min_date\"]=N_min_date_smooth\n",
    "        output_ds[\"SIB_onset\"]=(output_ds.O2_thresh+ output_ds.S_set_thresh15+ output_ds.SIC_thresh)/3\n",
    "        output_ds[\"Lon\"]=convert_180_lon_to_360(ds1.Lon.values.mean())\n",
    "\n",
    "        MLD_maxt=ds1.MLD.where(ds1.MLD==ds1.MLD.max(), drop=True)[-1].JULD\n",
    "        MLD_mint=ds1.MLD.where(ds1.MLD==ds1.MLD.min(), drop=True)[-1].JULD\n",
    "        output_ds[\"MLD_maxt\"]=MLD_maxt.dt.dayofyear.values\n",
    "        output_ds[\"MLD_mint\"]=MLD_mint.dt.dayofyear.values\n",
    "        output_ds[\"MLD_max\"]=ds1.MLD.max().values\n",
    "        output_ds[\"MLD_min\"]=ds1.MLD.min().values\n",
    "        output_ds[\"median_light_sum\"]=ds1.median_light.sum().values\n",
    "        output_ds[\"SIC_last\"]=ds1.SIC.where(ds1.SIC==ds1.SIC.min(),drop=True)[0].JULD.dt.dayofyear.values\n",
    "        output_ds=output_ds.expand_dims(\"Float_ID\")\n",
    "        \n",
    "        output_df=output_ds.to_dataframe()\n",
    "        DF= DF.append(output_df)\n",
    "        \n",
    "        ##################writing out files for later plotting##############\n",
    "        \"\"\"ds1[\"dNdt\"]=dNdt\n",
    "        write_out_ds=xr.Dataset(coords={\"Float_ID\":float_ID.astype(np.int64), \"JULD\":ds1.JULD})\n",
    "        write_out_ds[\"Float_ID\"]=float_ID.astype(np.int64)\n",
    "        write_out_ds[\"MLD\"]=ds1.MLD\n",
    "        write_out_ds[\"Nint_min_date\"]=output_ds[\"Nint_min_date\"]\n",
    "        write_out_ds[\"NCP_daily\"]=ds1.dNdt*(-106/16)*(10**-6)\n",
    "        write_out_ds[\"Lat_bloomNCPpeak\"]=ds1.Lat.interp(JULD=output_ds.Nint_min_date)\n",
    "        write_out_ds[\"MLD_max\"]=ds1.MLD.max()\n",
    "        write_out_ds[\"Lon_bloomNCPpeak\"]=ds1.Lon.interp(JULD=output_ds.Nint_min_date)\n",
    "        write_out_ds[\"SIC15_duration\"]=len(ds1.SIC.where(ds1.SIC<.15,drop=True))\n",
    "        write_out_ds[\"SIC_min\"]=SIC_min_after_max.values\n",
    "        write_out_ds[\"ML_40\"]=len(ds1.MLD.where(ds1.MLD<40, drop=True))\n",
    "        write_out_ds[\"GI\"]=GI\n",
    "        write_out_ds[\"GI_Cp\"]=GI_C\n",
    "        write_out_ds[\"NO3_thresh\"]=NS_exceeds_set_thresh[-1].JULD.values\n",
    "        write_out_ds[\"O2_thresh\"]=O_exceeds_set_thresh[-1].JULD.values\n",
    "        write_out_ds[\"Salinity_thresh\"]=S_set_thresh15[-1].JULD.values\n",
    "        write_out_ds[\"SIC_thresh\"]=SIC_025.values\n",
    "        write_out_ds[\"NCP\"]=output_ds[\"NCP\"]\n",
    "        write_out_ds[\"fractionNCP\"]=output_ds[\"fractionNCP_atSIC0\"]\n",
    "        write_out_ds[\"GP\"]=output_ds[\"GP\"]\n",
    "        write_out_ds[\"Nint_max_date\"]=output_ds[\"Nint_max_date\"]\n",
    "        write_out_ds[\"SIC\"]=ds1.SIC\n",
    "        write_out_ds[\"median_light\"]=ds1.median_light\n",
    "        write_out_ds[\"median_light_sum\"]=output_ds[\"median_light_sum\"]\n",
    "        write_out_ds[\"ML_Cp\"]=ds1.ML_C_phyto\n",
    "        write_out_ds[\"ML_Chl\"]=ds1.ML_Chl_a\n",
    "        write_out_ds[\"ML_N\"]=ds1.ML_N\n",
    "        write_out_ds[\"ML_S\"]=ds1.ML_S\n",
    "        write_out_ds[\"ML_O\"]=ds1.ML_O\n",
    "        write_out_ds[\"SIC_last\"]=output_ds[\"SIC_last\"]\n",
    "        #Need to write out files to net cdf for later grouping and plotting\n",
    "        write_out_ds.to_netcdf(\"/ADDPathHere\"+str(float_ID.values)+\"_\"+str(output_ds.Year.values)+\"v2.nc\", encoding={\"JULD\":{'_FillValue': None}})\n",
    "\"\"\"\n",
    "    return DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF15_Timing=phenology_DF_daily(SIZ_Floats_1, 2015, 2016, slice(\"2015-06-15\", \"2016-05-15\"), slice(\"2015-07\", \"2016-04\"))\n",
    "DF16_Timing=phenology_DF_daily(SIZ_Floats_1, 2016, 2017, slice(\"2016-06-15\", \"2017-05-15\"), slice(\"2016-07\", \"2017-04\"))\n",
    "DF17_Timing=phenology_DF_daily(SIZ_Floats_1, 2017, 2018, slice(\"2017-06-15\", \"2018-05-15\"), slice(\"2017-07\", \"2018-04\"))\n",
    "DF18_Timing=phenology_DF_daily(SIZ_Floats_1, 2018, 2019, slice(\"2018-06-15\", \"2019-05-15\"), slice(\"2018-07\", \"2019-04\"))\n",
    "DF19_Timing=phenology_DF_daily(SIZ_Floats_1, 2019, 2020, slice(\"2019-06-15\", \"2020-05-15\"), slice(\"2019-07\", \"2020-05\"))\n",
    "DF20_Timing=phenology_DF_daily(SIZ_Floats_1, 2020, 2021, slice(\"2020-06-15\", \"2021-05-15\"), slice(\"2020-07\", \"2021-05\"))\n",
    "\n",
    "DF_Timing=pd.concat([DF15_Timing.reset_index([\"JULD\", \"ML\"], drop=True),DF16_Timing.reset_index([\"JULD\", \"ML\"], drop=True), DF17_Timing.reset_index([\"JULD\", \"ML\"], drop=True),DF18_Timing.reset_index([\"JULD\", \"ML\"], drop=True), DF19_Timing.reset_index([\"JULD\", \"ML\"], drop=True), DF20_Timing.reset_index([\"JULD\", \"ML\"], drop=True)])\n",
    "DS_Timing=DF_Timing.to_xarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_flts_bySICday=pd.DataFrame()\n",
    "\n",
    "for i in range(len(All_flts_files)):\n",
    "    ds=xr.open_dataset(All_flts_files[i])\n",
    "    ds[\"fltyear\"]=str(ds.Float_ID[0].values)+str(ds.JULD[0].dt.year.values)\n",
    "    ds[\"NCP_daily\"]=ds.NCP_daily\n",
    "    ds[\"NCP_10day\"]=ds.NCP_daily.resample(JULD=\"10D\").mean()\n",
    "    ds[\"SIB_onset\"]=np.round(np.mean([ds.O2_thresh.dt.dayofyear.values, ds.Salinity_thresh.dt.dayofyear.values, ds.SIC_thresh.dt.dayofyear.values]))\n",
    "    ds=ds.assign_coords({\"dayofyear\": ds.JULD.dt.floor(\"D\").dt.dayofyear})\n",
    "    SIB_date=ds.where(ds.dayofyear==ds.SIB_onset.astype(\"int64\"),drop=True).JULD.dt.floor(\"D\")\n",
    "    \n",
    "    #SIB_date=ds.sel(dayofyear=ds.SIB_onset, method=\"nearest\").JULD.dt.floor(\"D\")\n",
    "    #mask data before sea ice breakup \n",
    "    ds=ds.where(ds.JULD> SIB_date.values)\n",
    "    days=ds.JULD.dt.floor(\"D\")\n",
    "    SIC_last=ds.SIC.where(ds.SIC==ds.SIC.min(),drop=True).JULD[0].dt.floor(\"D\")\n",
    "    print(SIC_last)\n",
    "    SIC_days=np.zeros(len(days))\n",
    "    for d in range(len(days)):\n",
    "        SIC_days[d]=(days[d]-SIC_last).dt.days.values\n",
    "    SIC_days=xr.DataArray(data=SIC_days, dims=ds.JULD.dims, coords=ds.JULD.coords)\n",
    "    ds=ds.assign_coords({\"SIC_days\":SIC_days})\n",
    "    ds=ds.swap_dims({\"JULD\":\"SIC_days\"})\n",
    "    if np.all(np.diff(ds.SIC_days.values)) == False:\n",
    "        print(SIC_days.values)\n",
    "    output_ds=xr.Dataset(coords={\"fltyear\":ds.fltyear, \"SIC_days\":ds.SIC_days})\n",
    "    output_ds[\"Float_ID\"]=ds.Float_ID.values\n",
    "    output_ds[\"NCP_daily\"]=ds.NCP_daily\n",
    "    output_ds[\"NCP_10day\"]=ds.NCP_10day\n",
    "    output_ds[\"SIC\"]=ds.SIC\n",
    "    output_ds[\"NCP\"]=ds.NCP\n",
    "    output_ds[\"SIB_onset\"]=ds.SIB_onset\n",
    "    output_ds[\"median_light\"]=ds.median_light\n",
    "    output_ds[\"median_light_cumsum\"]=(ds.median_light).cumsum()\n",
    "    \n",
    "    output_ds[\"ML_Cp\"]=ds.ML_Cp\n",
    "    output_ds[\"ML_Chl\"]=ds.ML_Chl\n",
    "    \n",
    "    \n",
    "    #output_ds=output_ds.expand_dims(\"fltyear\")\n",
    "    output_df=output_ds.to_dataframe()\n",
    "    \n",
    "    All_flts_bySICday=All_flts_bySICday.append(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise(row):  \n",
    "    if row['SIB_onset'] <= 290:\n",
    "        return \"Early SIB\"\n",
    "    elif row['SIB_onset'] >= 310:\n",
    "        return \"Late SIB\"\n",
    "    elif row['SIB_onset'] > 290  and row['SIB_onset'] < 310:\n",
    "        return 'mid'\n",
    "\n",
    "    \n",
    "df_late=All_flts_bySICday.where(All_flts_bySICday.SIB_onset>=310)\n",
    "df_early=All_flts_bySICday.where(All_flts_bySICday.SIB_onset<=290)\n",
    "\n",
    "\n",
    "All_flts_bySICday['SIB_group'] = All_flts_bySICday.apply(lambda row: categorise(row), axis=1)\n",
    "\n",
    "All_slicedb4_SIB_2_SIR=All_flts_bySICday.reset_index([\"SIC_days\"])\n",
    "All_slicedb4_SIB_2_SIR=All_slicedb4_SIB_2_SIR[All_slicedb4_SIB_2_SIR[\"SIC_days\"]<0]\n",
    "All_slicedb4_SIB_2_SIR=All_slicedb4_SIB_2_SIR[All_slicedb4_SIB_2_SIR[\"SIC_days\"]>-50]\n",
    "\n",
    "All_slicedaft_SIR=All_flts_bySICday.reset_index([\"SIC_days\"])\n",
    "All_slicedaft_SIR=All_slicedaft_SIR[All_slicedaft_SIR[\"SIC_days\"]<50]\n",
    "All_slicedaft_SIR=All_slicedaft_SIR[All_slicedaft_SIR[\"SIC_days\"]>0]\n",
    "\n",
    "All_sliced_50days=All_flts_bySICday.reset_index([\"SIC_days\"])\n",
    "All_sliced_50days=All_sliced_50days[All_sliced_50days[\"SIC_days\"]<50]\n",
    "All_sliced_50days=All_sliced_50days[All_sliced_50days[\"SIC_days\"]>-50]\n",
    "\n",
    "\n",
    "df_early_sliced=df_early.reset_index([\"SIC_days\"])\n",
    "df_early_sliced=df_early_sliced[df_early_sliced[\"SIC_days\"]<50]\n",
    "df_early_sliced=df_early_sliced[df_early_sliced[\"SIC_days\"]>-50]\n",
    "\n",
    "df_late_sliced=df_late.reset_index([\"SIC_days\"])\n",
    "df_late_sliced=df_late_sliced[df_late_sliced[\"SIC_days\"]<50]\n",
    "df_late_sliced=df_late_sliced[df_late_sliced[\"SIC_days\"]>-50]\n",
    "\n",
    "\n",
    "#define bins\n",
    "groups = pd.cut(df_SIB_2_SIR_early_sliced[\"SIC_days\"], 10, right=True, include_lowest=True)\n",
    "\n",
    "#display bin count by group variable\n",
    "grouped_mean_early=df_SIB_2_SIR_early_sliced.groupby(groups).mean()\n",
    "grouped_count_early=df_SIB_2_SIR_early_sliced.groupby(groups).count()\n",
    "\n",
    "groups = pd.cut(df_SIB_2_SIR_late_sliced[\"SIC_days\"], 10, right=True, include_lowest=True)\n",
    "\n",
    "#display bin count by group variable\n",
    "grouped_mean_late=df_SIB_2_SIR_late_sliced.groupby(groups).mean()\n",
    "grouped_count_late=df_SIB_2_SIR_late_sliced.groupby(groups).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_flts_DF=pd.DataFrame()\n",
    "\n",
    "for i in range(len(All_flts_files)):\n",
    "    ds=xr.open_dataset(All_flts_files[i])\n",
    "    ds=ds.sel(JULD=slice(ds.Nint_max_date[0].values, ds.Nint_min_date[0].values))\n",
    "    ds[\"NCP_daily\"]=ds.NCP_daily\n",
    "    ds[\"NCP_cumsum\"]=ds.NCP_daily.cumsum()\n",
    "    ds[\"fraction_NCP\"]=ds.NCP_daily.cumsum()/ds.NCP\n",
    "    ds[\"SIB_onset\"]=np.mean([ds.O2_thresh.dt.dayofyear.values, ds.Salinity_thresh.dt.dayofyear.values, ds.SIC_thresh.dt.dayofyear.values])\n",
    "    days=ds.JULD.dt.floor(\"D\")\n",
    "    SIC_last=ds.SIC.where(ds.SIC==ds.SIC.min(),drop=True)[0].JULD.dt.floor(\"D\")\n",
    "    SIC_days=np.zeros(len(days))\n",
    "    for d in range(len(days)):\n",
    "        SIC_days[d]=(days[d]-SIC_last).dt.days.values\n",
    "    SIC_days=xr.DataArray(data=SIC_days, dims=ds.JULD.dims, coords=ds.JULD.coords)\n",
    "    ds=ds.assign_coords({\"SIC_days\":SIC_days})\n",
    "    ds=ds.swap_dims({\"JULD\":\"SIC_days\"})\n",
    "    if np.all(np.diff(ds.SIC_days.values)) == False:\n",
    "        print(SIC_days.values)\n",
    "    output_ds=xr.Dataset(coords={ \"SIC_days\":ds.SIC_days})\n",
    "    output_ds[\"Float_ID\"]=ds.Float_ID.values\n",
    "    output_ds[\"SIC\"]=ds.SIC\n",
    "    output_ds[\"FracNCP\"]=ds.fraction_NCP\n",
    "    \n",
    "    output_ds=output_ds.expand_dims(\"fltyear\")\n",
    "    output_df=output_ds.to_dataframe()\n",
    "    \n",
    "    All_flts_DF=All_flts_DF.append(output_df)\n",
    "    \n",
    "\n",
    "ds_all_flts=xr.Dataset()\n",
    "\n",
    "ds_all_flts[\"FracNCP_mean\"]=All_flts_DF[\"FracNCP\"].groupby(\"SIC_days\").mean()\n",
    "ds_all_flts[\"FracNCP_std\"]=All_flts_DF[\"FracNCP\"].groupby(\"SIC_days\").std()\n",
    "ds_all_flts[\"flt_count\"]=All_flts_DF[\"SIC\"].groupby(\"SIC_days\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SO_raster=rxr.open_rasterio(\"/IBCSO_v2_bed_RGB.tif\")\n",
    "mpl.rcParams.update({'font.size': 18})\n",
    "fig, axis = plt.subplots(\n",
    "    1, 1, subplot_kw=dict(projection=ccrs.Stereographic(central_latitude=-90)), figsize=(12,15), dpi=300\n",
    ")\n",
    "\n",
    "SO_raster.plot.imshow(ax=axis)\n",
    "\n",
    "\n",
    "for i in range(len(All_flts_files)):\n",
    "    ds=xr.open_dataset(All_flts_files[i])\n",
    "    ds[\"SIB_onset\"]=np.mean([ds.O2_thresh.dt.dayofyear.values, ds.Salinity_thresh.dt.dayofyear.values, ds.SIC_thresh.dt.dayofyear.values])\n",
    "    \n",
    "    im=ds.plot.scatter(ax=axis,x=\"Lon_bloomNCPpeak\", y=\"Lat_bloomNCPpeak\", hue=\"NCP\",cmap=\"plasma\", vmin=.09, vmax=4.25, add_guide=False,\n",
    "                           transform=ccrs.PlateCarree(),  s=80)\n",
    "\n",
    "\n",
    "\n",
    "cbar=fig.colorbar(im ,orientation='vertical', shrink=.5)\n",
    "cbar.set_label('bNCP [mol C m$^{-2}$ bloom$^{-1}$]', rotation=270, labelpad=20)\n",
    "axis.gridlines(color='.25', ylocs=np.arange(-90,50, 5), draw_labels=True)\n",
    "\n",
    "#Limit the map to -50 degrees latitude and below.\n",
    "axis.set_extent([-180, 180, -90, -55], ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "axis.set_title(\"\")\n",
    "\n",
    "# Compute a circle in axes coordinates, which we can use as a boundary\n",
    "# for the map. We can pan/zoom as much as we like - the boundary will be\n",
    "# permanently circular.\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)\n",
    "\n",
    "axis.set_boundary(circle, transform=axis.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax6) = plt.subplots(2,1, figsize=(12,17),constrained_layout=False)#,gridspec_kw={'height_ratios': [6, 1, 6]})\n",
    "for i in range(len(All_flts_files)):\n",
    "    \n",
    "    ds=xr.open_dataset(All_flts_files[i])\n",
    "    if ds.Float_ID==\"5904471\" and ds.JULD[0].dt.year==2018:\n",
    "        ds=ds.sel(JULD=slice(\"2018-08\", \"2019-04\"))\n",
    "    #mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "        mpl.rcParams.update({'font.size': 24})\n",
    "        #mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "        mpl.rcParams['lines.markersize'] = 14\n",
    "\n",
    "        ds.ML_N.plot(ax=ax1,color=\"red\", yincrease=False,linewidth=4, label=\"[NO$_3$$^-$] \")\n",
    "\n",
    "        axO=ax1.twinx()\n",
    "        axSICtop=ax1.twinx()\n",
    "        axchl=ax1.twinx()\n",
    "        axcp=ax1.twinx()\n",
    "        axS=ax6.twinx()\n",
    "        axRAD=ax6.twinx()\n",
    "        axSICbot=ax6.twinx()\n",
    "        \n",
    "                             \n",
    "        ds.ML_O.plot(ax=axO,color=\"orange\",linewidth=4,label=\"[O\"+\"$_{2}$\"+\"]\")\n",
    "        ds.ML_Chl.plot(ax=axchl,color=\"magenta\",linewidth=4,label=\"[Chl] \") \n",
    "        ds.ML_Cp.plot(ax=axcp,color=\"b\",linewidth=4, label=\"[C$_p$]\")\n",
    "        ds.SIC.plot(ax=axSICtop, label=\"SIC\",alpha=0.2, linewidth=8, color=\"cornflowerblue\")\n",
    "        axSICtop.fill_between(ds.JULD.values,ds.SIC.values, alpha=0.2, color=\"cornflowerblue\")\n",
    "        ds.ML_S.plot(ax=axS, linewidth=4, color=\"slategrey\",label=\"Salinity\")\n",
    "        (ds.SIC*100).plot(ax=axSICbot,alpha=0.2, label=\"SIC [%]\")\n",
    "        axSICbot.fill_between(ds.JULD.values,(ds.SIC*100).values, alpha=0.2,linewidth=8, color=\"cornflowerblue\")\n",
    "        ds.median_light.plot(ax=axRAD, color=\"darkviolet\",linewidth=4, label=\"Median mixed \\n layer light\")\n",
    "\n",
    "        ax1.scatter(x=ds.NO3_thresh.values, y=ds.ML_N.sel(JULD=ds.NO3_thresh.values).values,  color=\"r\",label=\"[NO\"+\"$_{3}$\"+\"-] decrease\")\n",
    "        axO.scatter(x=ds.O2_thresh.values, y=ds.ML_O.sel(JULD=ds.O2_thresh.values).values ,color=\"darkorange\", marker=\"s\",label=\"[O\"+\"$_{2}$\"+\"] increase\")\n",
    "        axcp.scatter(x=ds.GI_Cp.values, y=ds.ML_Cp.interp(JULD=ds.GI_Cp.values).values, marker=\"o\",color=\"blue\", label=\"GI_Cp\")\n",
    "        axchl.scatter(x=ds.GI.values, y=ds.ML_Chl.interp(JULD=ds.GI.values).values, marker=\"*\",color=\"magenta\", label=\"GI\")\n",
    "        axS.scatter(x=ds.Salinity_thresh.values, y=ds.ML_S.sel(JULD=ds.Salinity_thresh.values).values, color=\"slategrey\", label=\"Salinity decrease\")\n",
    "        ds.MLD.plot(ax=ax6,color=\"black\",yincrease=False, label=\"MLD\", linewidth=3)\n",
    "        \n",
    "        \n",
    "        ax1.set_xlabel(\"\")\n",
    "        \n",
    "        \n",
    "        axSICtop.get_xaxis().set_visible(False)\n",
    "        axO.get_xaxis().set_visible(False)\n",
    "        axchl.get_xaxis().set_visible(False)\n",
    "        axcp.get_xaxis().set_visible(False)\n",
    "        \n",
    "        axcp.set_yscale(\"log\")\n",
    "        axchl.set_yscale(\"log\")\n",
    "        axcp.spines[\"right\"].set_position((\"axes\", 1.18))\n",
    "\n",
    "        axO.spines[\"right\"].set_position((\"axes\", -.22))\n",
    "        \n",
    "        axS.spines[\"right\"].set_color('grey')\n",
    "        axRAD.spines[\"right\"].set_position((\"axes\", 1.18))\n",
    "\n",
    "        axSICbot.spines[\"right\"].set_position((\"axes\", -.22))\n",
    "\n",
    "        axcp.yaxis.set_tick_params(which='both', size=12, width=2, direction='in')\n",
    "        axchl.yaxis.set_tick_params(which='both', size=12, width=2, direction='out')\n",
    "        \n",
    "        ax1.yaxis.set_tick_params(which='major', size=12, width=2, direction='in')\n",
    "        axO.yaxis.set_tick_params(which='major', size=12, width=2, direction='in')\n",
    "        axRAD.yaxis.set_tick_params(which='major', size=12, width=2, direction='in')\n",
    "\n",
    "        axSICbot.yaxis.set_label_coords(-.28, .5)\n",
    "        axO.yaxis.set_label_coords(-.28, .5)\n",
    "\n",
    "        axO.spines[\"right\"].set_color(\"darkorange\")\n",
    "        axcp.spines[\"right\"].set_color('blue')\n",
    "        ax6.spines[\"right\"].set_color(\"cornflowerblue\")\n",
    "        axchl.spines[\"right\"].set_color(\"magenta\")\n",
    "        ax1.spines[\"left\"].set_color(\"red\")\n",
    "        axRAD.spines[\"right\"].set_color(\"darkviolet\")\n",
    "        axSICbot.spines[\"right\"].set_color(\"cornflowerblue\")\n",
    "\n",
    "\n",
    "        ax1.tick_params(axis='y', colors='red')\n",
    "        axO.tick_params(axis='y', colors='darkorange')\n",
    "        axchl.tick_params(axis='y', colors='magenta', which='both')\n",
    "        axRAD.tick_params(axis='y', colors='darkviolet')\n",
    "        #axcp.tick_params(axis='y', colors='blue')\n",
    "        axcp.tick_params(axis='y', colors='blue', which='both')\n",
    "        axSICbot.tick_params(axis='y', colors='cornflowerblue')\n",
    "        axS.tick_params(axis='y', colors='grey')\n",
    "\n",
    "        ax1.set_ylabel(\"[NO\"+\"$_{3}$\"+\"$^-$] (µmol kg\"+\"$^{-1}$\"+\")\")\n",
    "        axO.set_ylabel(\"[O\"+\"$_{2}$\"+\"] (µmol kg\"+\"$^{-1}$\"+\")\")\n",
    "        axcp.set_ylabel(\"[C$_p$] (mg m\"+\"$^{-3}$\"+\")\")\n",
    "        axchl.set_ylabel(\"[Chl] (mg m\"+\"$^{-3}$\"+\")\")\n",
    "        ax6.set_ylabel(\"MLD [m]\")\n",
    "        axSICbot.set_ylabel(\"SIC [%]\")\n",
    "        axRAD.set_ylabel(\"Median mixed layer Light \\n (mol photon m\"+\"$^{-2}$\"+\" d\"+\"$^{-1}$\"+\")\")\n",
    "        axS.set_ylabel(\"Salinity\")\n",
    "        \n",
    "        ax1.yaxis.label.set_color('red')\n",
    "        axchl.yaxis.label.set_color('magenta')\n",
    "        axO.yaxis.label.set_color('darkorange')\n",
    "        axcp.yaxis.label.set_color('blue')\n",
    "        axSICbot.yaxis.label.set_color(\"cornflowerblue\")\n",
    "        axRAD.yaxis.label.set_color('darkviolet')\n",
    "        \n",
    "        axS.yaxis.label.set_color('grey')\n",
    "\n",
    "        ax6.xaxis.grid()\n",
    "        ax1.xaxis.grid()\n",
    "\n",
    "        \n",
    "        axSICtop.set_axis_off()\n",
    "        \n",
    "        #axSICbot.set_axis_off()\n",
    "\n",
    "        Oh, Ol=axO.get_legend_handles_labels()\n",
    "        Nh, Nl=ax1.get_legend_handles_labels()\n",
    "        Ch, Cl=axchl.get_legend_handles_labels()\n",
    "        Cph, Cpl=axcp.get_legend_handles_labels()\n",
    "        Sh, Sl=axS.get_legend_handles_labels()\n",
    "        SICh, SICl=axSICtop.get_legend_handles_labels()\n",
    "        MLDh, MLDl=ax6.get_legend_handles_labels()\n",
    "        RADh, RADl=axRAD.get_legend_handles_labels()\n",
    "       \n",
    "        lg1=axSICbot.legend([ MLDh[0],  Sh[0] , SICh[0], RADh[0]],[ MLDl[0], Sl[0],SICl[0], RADl[0]], loc=\"upper left\", bbox_to_anchor=(0.025, 0.85), framealpha=1,fontsize=\"x-small\")\n",
    "        lg2=axSICtop.legend([Nh[0], Oh[0], Ch[0], Cph[0]],[Nl[0], Ol[0],  Cl[0],Cpl[0]], loc=\"upper left\",bbox_to_anchor=(0.025, 0.85),framealpha=1,fontsize=\"x-small\")\n",
    "        frame1 = lg1.get_frame()\n",
    "        frame1.set_facecolor('white')\n",
    "        frame1.set_edgecolor('grey')\n",
    "        #frame1.set_zorder(30) \n",
    "\n",
    "        ax6.set_xlabel(\"\")\n",
    "        ax6.set_title(\"\")\n",
    "        axS.set_title(\"\")\n",
    "        axRAD.set_title(\"\")\n",
    "        axSICbot.set_title(\"\")\n",
    "        ax1.set_title(\"\")\n",
    "        axO.set_title(\"\")\n",
    "        axchl.set_title(\"\")\n",
    "        axSICtop.set_title(\"\")\n",
    "        axcp.set_title(\"\")\n",
    "        \n",
    "        ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "        ax6.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "        ax6.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "        \"\"\"ax1.xaxis.set_major_formatter(\n",
    "            mdates.ConciseDateFormatter(ax1.xaxis.get_major_locator()))\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        title=fig.suptitle(\"Ex. Float \"+str(ds.Float_ID[0].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(7,6))\n",
    "\n",
    "mpl.rcParams['lines.markersize'] = 9\n",
    "f=ax.scatter(x=DS_Timing.SIB_onset, y=DS_Timing.GI_C, color=\"b\", label=\"GI$_{Cp}$\", marker=\"^\", s=70)\n",
    "\n",
    "f=ax.scatter(x=DS_Timing.SIB_onset, y=DS_Timing.NO3_thresh, color=\"red\", label=\"[NO$_{3}^{-}$] drawdown\", s=70)\n",
    "\n",
    "bin260=DS_Timing.where(DS_Timing.SIB_onset>=255, drop=True)\n",
    "bin280=DS_Timing.where(DS_Timing.SIB_onset>=275, drop=True)\n",
    "bin300=DS_Timing.where(DS_Timing.SIB_onset>=295, drop=True)\n",
    "bin320=DS_Timing.where(DS_Timing.SIB_onset>=315, drop=True)\n",
    "\n",
    "bin260=bin260.where(bin260.SIB_onset<275, drop=True)\n",
    "bin280=bin280.where(bin280.SIB_onset<295, drop=True)\n",
    "bin300=bin300.where(bin300.SIB_onset<315, drop=True)\n",
    "\n",
    "Xval=np.array([265, 285, 305, 325])\n",
    "Nmean=np.array([bin260.NO3_thresh.mean().values, bin280.NO3_thresh.mean().values, bin300.NO3_thresh.mean().values, bin320.NO3_thresh.mean().values])\n",
    "Cmean=np.array([bin260.GI_C.mean().values, bin280.GI_C.mean().values, bin300.GI_C.mean().values, bin320.GI_C.mean().values])\n",
    "        \n",
    "\n",
    "Nstd=np.array([bin260.NO3_thresh.std().values, bin280.NO3_thresh.std().values, bin300.NO3_thresh.std().values, bin320.NO3_thresh.std().values])\n",
    "Cstd=np.array([bin260.GI_C.std().values, bin280.GI_C.std().values, bin300.GI_C.std().values, bin320.GI_C.std().values])\n",
    "\n",
    "\n",
    "ax.errorbar(Xval, Nmean, Nstd, linestyle='solid', linewidth=3, color=\"r\", marker=\"o\",fmt='_', capthick=2, capsize=4)\n",
    "ax.errorbar(Xval, Cmean, Cstd, linestyle='solid', linewidth=3, color=\"b\", marker=\"^\",fmt='_', capthick=2, capsize=4)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Intial sea ice breakup day\")\n",
    "ax.set_ylabel(\"Day of nitrate drawdown/GI$_{Cp}$\",fontsize=19)\n",
    "ax.set_xlim(240, 365)\n",
    "ax.set_ylim(240, 365)\n",
    "line=ax.plot([240,365], [240,365], color=\"orange\")\n",
    "\n",
    "ax.fill_between( np.arange(240, 365), y1=240, y2=np.arange(240, 365) , alpha=0.2, color=\"cornflowerblue\")\n",
    "ax.set_xticks([244, 274, 305, 335])\n",
    "ax.set_xticklabels(['Sept', 'Oct', 'Nov', \"Dec\"])\n",
    "ax.set_yticks([244, 274, 305, 335])\n",
    "ax.set_yticklabels(['Sept', 'Oct', 'Nov', \"Dec\"])\n",
    "#ax.xaxis.set_minor_locator(MultipleLocator(15))\n",
    "ax.tick_params(which='major', length=6)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "# Define bbox style\n",
    "box_style=dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "# Text inside a box\n",
    "plt.text(345,345, \"1:1\",{'color':'blue','size':18},bbox=box_style)\n",
    "\n",
    "\n",
    "ax.legend(fontsize=\"small\", loc='best', bbox_to_anchor=(.5, 0., .5, .3), markerfirst=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, (ax, ax2) = plt.subplots(1,2 , figsize=(16, 7), dpi=100)\n",
    "ax1=ax.twinx()\n",
    "mpl.rcParams.update({'font.size': 20, 'font.family':\"sans-serif\"})\n",
    "\n",
    "x=ds_all_flts.SIC_days\n",
    "y1=(ds_all_flts.FracNCP_mean)+ds_all_flts.FracNCP_std\n",
    "y2=(ds_all_flts).FracNCP_mean-ds_all_flts.FracNCP_std\n",
    "ds_all_flts.FracNCP_mean.plot(ax=ax)\n",
    "ax.fill_between(x,y1, y2, alpha=.25)\n",
    "ax.set_xlabel(\"Day relative to total sea ice retreat\")\n",
    "ax.set_ylabel(\"Fraction of total bNCP\")\n",
    "ax.set_xlim(-60, 50)\n",
    "ax.set_ylim(-.015, 1)\n",
    "ax.axvline(x=0, linestyle=\"solid\", color=\"black\", alpha=.8)\n",
    "ax.axhline(y=ds_all_flts.FracNCP_mean.sel(SIC_days=0).values, linestyle=\"dashed\", color=\"black\", alpha=.8)\n",
    "\n",
    "\n",
    "\n",
    "x1 = All_slicedb4_SIB_2_SIR['NCP_daily'].dropna().values*1000\n",
    "print(All_slicedb4_SIB_2_SIR[\"NCP_daily\"].mean())\n",
    "print(All_slicedb4_SIB_2_SIR[\"NCP_daily\"].std())\n",
    "\n",
    "x2 = All_slicedaft_SIR['NCP_daily'].dropna().values*1000\n",
    "print(All_slicedaft_SIR[\"NCP_daily\"].mean())\n",
    "print(All_slicedaft_SIR[\"NCP_daily\"].std())\n",
    "\n",
    "\n",
    "sns.histplot(x1, stat=\"probability\", ax=ax2, bins=40, binrange=(-30, 85),label=\"Partial sea ice mean:\\n\"+str(All_slicedb4_SIB_2_SIR[\"NCP_daily\"].mean()*1000)[0:2]) \n",
    "sns.histplot(x2, stat=\"probability\", ax=ax2, bins=40, binrange=(-30, 85),label=\"Open water mean:\\n\"+str(All_slicedaft_SIR[\"NCP_daily\"].mean()*1000)[0:2])\n",
    "\n",
    "\n",
    "ax2.set_title('Probability Histogram of Daily NCP \\n before and after total sea ice retreat', fontsize=21)\n",
    "ax2.set_ylabel('Probability')\n",
    "ax2.set_xlabel(\"NCP (mmol C m$^{-2}$ d$^{-1}$)\")\n",
    "ax2.legend(prop={'size': 15})\n",
    "ax2.axvline(x=0, color=\"black\")\n",
    "\n",
    "\n",
    "\n",
    "ax.text(-0.1, 1.1, \"a\", transform=ax.transAxes, \n",
    "            size=20, weight='bold')\n",
    "ax2.text(-0.1, 1.1, \"b\", transform=ax2.transAxes, \n",
    "            size=20, weight='bold')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sma\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['lines.markersize'] = 9\n",
    "model = LinearRegression()\n",
    "mpl.rcParams.update({'font.size': 20})\n",
    "fig, (ax, ax2)= plt.subplots(1,2,figsize=(16,7))\n",
    "reg = LinearRegression().fit(DS_Timing.SIB_onset.values.reshape(-1, 1), DS_Timing.NCP.values)\n",
    "print(reg.score(DS_Timing.SIB_onset.values.reshape(-1, 1), DS_Timing.NCP.values))\n",
    "\n",
    "ax1=ax.twiny()\n",
    "ax.set_xticks([245, 260, 275, 290, 305, 320])\n",
    "ax1.set_xticks([244, 259, 274, 289.5, 305, 320, 335])\n",
    "ax1.set_xticklabels(['Sept',\"\", 'Oct', \"\",'Nov', \"\",\"Dec\"])\n",
    "\n",
    "DS_Timing.plot.scatter(ax=ax, x=\"SIB_onset\", y=\"NCP\")\n",
    "z = np.polyfit(DS_Timing.SIB_onset.values, DS_Timing.NCP.values, 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(DS_Timing.SIB_onset.values, p(DS_Timing.SIB_onset.values),\"r\", label=\"r$^2$=\"+str(np.round(reg.score(DS_Timing.SIB_onset.values.reshape(-1, 1), DS_Timing.NCP.values),3))[0:4]+\"\\n P<.001\")\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"bNCP (mol C m$^{-2}$ bloom$^{-1}$)\")\n",
    "ax.set_xlabel(\"Sea ice breakup day\")\n",
    "ax1.set_xlabel(\"\")\n",
    "ax.set_xlim(242, 337)\n",
    "ax1.set_xlim(242, 337)\n",
    "\n",
    "x=grouped_mean_early.SIC_days\n",
    "y1=((grouped_mean_early.NCP_daily-grouped_mean_late.NCP_daily)+(grouped_mean_early.NCP_daily-grouped_mean_late.NCP_daily).std())*1000\n",
    "y2=((grouped_mean_early.NCP_daily-grouped_mean_late.NCP_daily)-(grouped_mean_early.NCP_daily-grouped_mean_late.NCP_daily).std())*1000\n",
    "y1a=(grouped_mean_early.median_light-grouped_mean_late.median_light)-(grouped_mean_early.median_light-grouped_mean_late.median_light).std()\n",
    "y2a=(grouped_mean_early.median_light-grouped_mean_late.median_light)+(grouped_mean_early.median_light-grouped_mean_late.median_light).std()\n",
    "ax3=ax2.twinx()\n",
    "line1=(grouped_mean_early.NCP_daily-grouped_mean_late.NCP_daily)*1000#.plot(ax=ax, label=\"Daily NCP difference\", color=\"navy\")\n",
    "lns1=ax2.plot(x, line1, color=\"navy\", label=\"Daily NCP difference\")\n",
    "ax2.fill_between(x, y1, y2, alpha=.25, color=\"navy\")\n",
    "line2=(grouped_mean_early.median_light-grouped_mean_late.median_light)#.plot(ax=ax1, label=\"Daily light difference\", color=\"cyan\")\n",
    "lns2=ax3.plot(x, line2,label=\"Daily light difference\", color=\"darkturquoise\")\n",
    "ax3.fill_between(x, y1a, y2a, alpha=.25, color=\"darkturquoise\")\n",
    "\n",
    "ax2.set_xlabel(\"Day relative to total sea ice retreat\")\n",
    "ax2.set_ylabel(\"NCP rate\")\n",
    "ax2.set_xticks([-50, -25,0, 25 ,50])\n",
    "#ax3.set_xticks([-50, -30, -15,0,15,30,50])\n",
    "\n",
    "ax3.set_ylim(-8,8)\n",
    "ax2.set_ylim(-10,10)\n",
    "\n",
    "\n",
    "ax2.spines[\"left\"].set_color(\"navy\")\n",
    "ax3.spines[\"right\"].set_color('darkturquoise')\n",
    "\n",
    "ax2.tick_params(axis='y', colors='navy')\n",
    "ax3.tick_params(axis='y', colors='darkturquoise')\n",
    "\n",
    "ax2.yaxis.label.set_color(\"navy\")\n",
    "ax3.yaxis.label.set_color('darkturquoise')\n",
    "\n",
    "ax2.set_title(\"Early sea ice breakup minus late \\n sea ice breakup NCP and light availability\", fontsize=21)\n",
    "ax3.set_ylabel(\"Median mixed layer light \\n (mol photon m\"+\"$^{-2}$\"+\" d\"+\"$^{-1}$\"+\")\")\n",
    "ax2.set_ylabel(\"NCP (mmol C m$^{-2}$ d$^{-1}$)\")\n",
    "ax2.axhline(color=\"black\")\n",
    "\n",
    "lns = lns1+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax2.legend(lns, labs, loc=\"lower right\")\n",
    "\n",
    "ax.text(-0.1, 1.1, \"a\", transform=ax.transAxes, \n",
    "            size=20, weight='bold')\n",
    "ax2.text(-0.1, 1.1, \"b\", transform=ax2.transAxes, \n",
    "            size=20, weight='bold')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) =plt.subplots(2,1, figsize=(8, 13))\n",
    "#plt.rcParams.update({'font.size': 22})\n",
    "mpl.rcParams.update({'font.size': 18})\n",
    "        \n",
    "mpl.rcParams['lines.markersize'] = 9\n",
    "f=ax.scatter(x=DS_Timing.O2_thresh, y=DS_Timing.GI_C, color=\"b\", label=\"GI$_{Cp}$\", marker=\"^\", s=70)\n",
    "\n",
    "f=ax.scatter(x=DS_Timing.O2_thresh, y=DS_Timing.NO3_thresh, color=\"red\", label=\"[NO$_{3}^{-}$] decrease\", s=70)\n",
    "f=ax.scatter(x=DS_Timing.O2_thresh, y=DS_Timing.S_set_thresh15, color=\"grey\", marker=\"s\", label=\"Salinity decrease\", s=70)\n",
    "\n",
    "bin250=DS_Timing.where(DS_Timing.O2_thresh>=255, drop=True)\n",
    "bin270=DS_Timing.where(DS_Timing.O2_thresh>=275, drop=True)\n",
    "bin290=DS_Timing.where(DS_Timing.O2_thresh>=295, drop=True)\n",
    "bin310=DS_Timing.where(DS_Timing.O2_thresh>=315, drop=True)\n",
    "\n",
    "bin250=bin250.where(bin250.O2_thresh<275, drop=True)\n",
    "bin270=bin270.where(bin270.O2_thresh<295, drop=True)\n",
    "bin290=bin290.where(bin290.O2_thresh<315, drop=True)\n",
    "\n",
    "Xval=np.array([265, 285, 305, 325])\n",
    "Nmean=np.array([bin250.NO3_thresh.mean().values, bin270.NO3_thresh.mean().values, bin290.NO3_thresh.mean().values, bin310.NO3_thresh.mean().values])\n",
    "Smean=np.array([bin250.S_set_thresh15.mean().values, bin270.S_set_thresh15.mean().values, bin290.S_set_thresh15.mean().values, bin310.S_set_thresh15.mean().values])\n",
    "Cmean=np.array([ bin250.GI_C.mean().values, bin270.GI_C.mean().values, bin290.GI_C.mean().values, bin310.GI_C.mean().values])\n",
    "\n",
    "\n",
    "Nstd=np.array([ bin250.NO3_thresh.std().values, bin270.NO3_thresh.std().values, bin290.NO3_thresh.std().values, bin310.NO3_thresh.std().values])\n",
    "Sstd=np.array([ bin250.S_set_thresh15.std().values, bin270.S_set_thresh15.std().values, bin290.S_set_thresh15.std().values, bin310.S_set_thresh15.std().values])\n",
    "Cstd=np.array([ bin250.GI_C.std().values, bin270.GI_C.std().values, bin290.GI_C.std().values, bin310.GI_C.std().values])\n",
    "\n",
    "\n",
    "ax.errorbar(Xval, Nmean, Nstd, linestyle='solid', linewidth=3, color=\"r\", marker=\"o\",fmt='_', capthick=2, capsize=4)\n",
    "ax.errorbar(Xval, Smean, Sstd, linestyle='solid', linewidth=3, color=\"grey\", marker=\"s\",fmt='_', capthick=2, capsize=4)\n",
    "ax.errorbar(Xval, Cmean, Cstd, linestyle='solid', linewidth=3, color=\"b\", marker=\"^\",fmt='_', capthick=2, capsize=4)\n",
    "\n",
    "ax.set_xlabel(\"Day of oxygen increase\",fontsize=19)\n",
    "\n",
    "ax.set_ylabel(\"Day of tracer change\",fontsize=19)\n",
    "ax.set_xlim(240, 360)\n",
    "ax.set_ylim(240, 360)\n",
    "line=ax.plot([240,365], [240,365], color=\"orange\")\n",
    "\n",
    "ax.fill_between( np.arange(240, 365), y1=240, y2=np.arange(240, 365) , alpha=0.2, color=\"cornflowerblue\")\n",
    "ax.set_xticks([244, 274, 305, 335])\n",
    "ax.set_xticklabels(['Sept', 'Oct', 'Nov', \"Dec\"])\n",
    "ax.set_yticks([244, 274, 305, 335])\n",
    "ax.set_yticklabels(['Sept', 'Oct', 'Nov', \"Dec\"])\n",
    "#ax.xaxis.set_minor_locator(MultipleLocator(15))\n",
    "ax.tick_params(which='major', length=6)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "# Define bbox style\n",
    "box_style=dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "# Text inside a box\n",
    "ax.text(350,351, \"1:1\",{'color':'blue','size':18},bbox=box_style)\n",
    "\n",
    "#ax.set_title(\"NO$_{3}^{-}$/C-phyto change vs Sea Ice breakup\",fontsize=21) #\"$O_{2}$\"\n",
    "#ax.set_title(str((DS_daily.Cp_at_GI_C_mgm3/DS_daily.Chla_at_GI_Cmgm3).mean().values)[0:4]+\"mean C:CHl at GI_C\")\n",
    "ax.legend(fontsize=\"small\", loc='best', bbox_to_anchor=(.5, 0., .5, .3), markerfirst=False)\n",
    "\n",
    "slope_=np.zeros((1))\n",
    "\n",
    "for flt in range(len(All_flts_files)):\n",
    "    ds1=xr.open_dataset(All_flts_files[flt])\n",
    "    SIC_lower=ds1.where(ds1.JULD> ds1.SIC_thresh.values, drop=True).where(ds1.SIC>.6, drop=True)\n",
    "    SIC_lower[\"norm_S\"]=SIC_lower.ML_S-SIC_lower.ML_S.mean()\n",
    "    slope_flt, b_flt = np.polyfit(SIC_lower.ML_S.values.reshape(-1), SIC_lower.SIC.values.flatten(), 1)\n",
    "    SIC_lower.plot.scatter(ax=ax1, x=\"norm_S\", y=\"SIC\", color=\"maroon\", alpha=.7, s=4)\n",
    "    slope_=np.append(slope_, slope_flt)\n",
    "    \n",
    "ax1.set_xlabel(\"Normalized mixed layer salinity\")\n",
    "ax1.set_ylabel(\"Sea ice concentration\")\n",
    "\n",
    "slope_=slope_[1:]\n",
    "q25, q75 = np.percentile(slope_, 25), np.percentile(slope_, 75)\n",
    "iqr = q75 - q25\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in slope_ if x < lower or x > upper]\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in slope_ if x > lower and x < upper]\n",
    "print(np.mean(outliers_removed), \"mean no outlier\")\n",
    "# add arbitrary line with mean slope (no outliers) \n",
    "x_vals = np.array(ax1.get_xlim())\n",
    "y_vals = ax1.get_ylim()[0] + np.mean(outliers_removed) * x_vals\n",
    "ax1.plot(x_vals, y_vals, '--', label= \"slope= 1.6\")\n",
    "ax1.set_xlim(-.5, .5)\n",
    "ax1.set_ylim(.6, .98)\n",
    "\n",
    "fig.tight_layout()\n",
    "ax.text(-0.1, .99, \"a\", transform=ax.transAxes, \n",
    "            size=20, weight='bold')\n",
    "ax1.text(-0.1, .99, \"b\", transform=ax1.transAxes, \n",
    "            size=20, weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax) = plt.subplots(1,2, figsize=(15,8))\n",
    "\n",
    "mpl.rcParams.update({'font.size': 20, 'font.family': \"sans-serif\"})\n",
    "DS_Timing.plot.scatter(ax=ax, x=\"Chl_thresh\", y=\"NO3_thresh\", s=32, label=\"[NO$_3^-$] drawdown day\")\n",
    "DS_Timing.plot.scatter(ax=ax, x=\"Chl_thresh\", y=\"GI_C\", color=\"orange\", s=32, label=\"GI$_{Cp}$\")\n",
    "ax.set_xlim(230, 365)\n",
    "ax.set_ylim(230, 365)\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.set_xlabel(\"[Chl] threshold day\")\n",
    "ax.set_ylabel(\"GI$_{Cp}$/Nitrate drawdown day\")\n",
    "ax.plot([240, 365], [240, 365], 'k-')\n",
    "ax.set_xticks([244, 274, 305, 335])\n",
    "ax.set_xticklabels(['Sept', 'Oct', 'Nov', \"Dec\"])\n",
    "ax.set_yticks([244, 274, 305, 335])\n",
    "ax.set_yticklabels(['Sept', 'Oct', 'Nov', \"Dec\"])\n",
    "\n",
    "DS_Timing.plot.scatter(ax=ax1, x=\"GI\", y=\"NO3_thresh\", s=32, label=\"[NO$_3^-$] drawdown day\")\n",
    "DS_Timing.plot.scatter(ax=ax1, x=\"GI\", y=\"GI_C\", color=\"orange\", s=32, label=\"GI$_{Cp}$\")\n",
    "ax1.set_xlim(230, 365)\n",
    "ax1.set_ylim(230, 365)\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_xlabel(\"GI$_{Chl}$ day\")\n",
    "ax1.set_ylabel(\"GI$_{Cp}$/Nitrate drawdown day\")\n",
    "ax1.plot([240, 365], [240, 365], 'k-')\n",
    "ax1.set_xticks([244, 274, 305, 335])\n",
    "ax1.set_xticklabels(['Sept', 'Oct', 'Nov', \"Dec\"])\n",
    "ax1.set_yticks([244, 274, 305, 335])\n",
    "ax1.set_yticklabels(['Sept', 'Oct', 'Nov', \"Dec\"])\n",
    "\n",
    "#set aspect ratio to 1\n",
    "ratio = 1.0\n",
    "x_left, x_right = ax.get_xlim()\n",
    "y_low, y_high = ax.get_ylim()\n",
    "ax.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "#set aspect ratio to 1\n",
    "ratio1 = 1.0\n",
    "x_left1, x_right1 = ax1.get_xlim()\n",
    "y_low1, y_high1 = ax1.get_ylim()\n",
    "ax1.set_aspect(abs((x_right1-x_left1)/(y_low1-y_high1))*ratio1)\n",
    "\n",
    "ax.text(-0.1, 1.1, \"b\", transform=ax.transAxes, \n",
    "            size=20, weight='bold')\n",
    "ax1.text(-0.1, 1.1, \"a\", transform=ax1.transAxes, \n",
    "            size=20, weight='bold')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_flts_bySIB=pd.DataFrame()\n",
    "for i in range(len(All_flts_files)):\n",
    "    ds=xr.open_dataset(All_flts_files[i])\n",
    "    ds[\"fltyear\"]=str(ds.Float_ID.values)+str(ds.JULD[0].dt.year.values)\n",
    "    ds[\"NCP_daily\"]=ds.NCP_daily\n",
    "    ds[\"NCP_cumsum\"]=ds.NCP_daily.cumsum()\n",
    "    ds[\"fraction_NCP\"]=ds.NCP_daily.cumsum()/ds.NCP\n",
    "    ds[\"SIB_onset\"]=np.mean([ds.O2_thresh.dt.dayofyear.values, ds.Salinity_thresh.dt.dayofyear.values, ds.SIC_thresh.dt.dayofyear.values])\n",
    "    \n",
    "    ds[\"SIB_onset\"]=np.round(ds.SIB_onset.values)\n",
    "    \n",
    "    ds[\"days\"]=ds.JULD.dt.floor(\"D\").dt.dayofyear\n",
    "    \n",
    "    days=ds.JULD.dt.floor(\"D\")\n",
    "    \n",
    "    SIB_date=ds.days.where(ds.days==ds.SIB_onset,drop=True)[0].JULD.dt.floor(\"D\")\n",
    "    \n",
    "    SIB_days=np.zeros(len(days))\n",
    "    for d in range(len(days)):\n",
    "        SIB_days[d]=(days[d]-SIB_date).dt.days.values\n",
    "    \n",
    "    SIB_days=xr.DataArray(data=SIB_days, dims=ds.JULD.dims, coords=ds.JULD.coords)\n",
    "    ds=ds.assign_coords({\"SIB_days\":SIB_days})\n",
    "    ds=ds.swap_dims({\"JULD\":\"SIB_days\"})\n",
    "    \n",
    "    if np.all(np.diff(ds.SIB_days.values)) == False:\n",
    "        print(SIB_days.values)\n",
    "    \n",
    "    output_ds=xr.Dataset(coords={\"fltyear\":ds.fltyear, \"SIB_days\":ds.SIB_days})\n",
    "    \n",
    "    output_ds[\"NCP_daily\"]=ds.NCP_daily\n",
    "    output_ds[\"SIC\"]=ds.SIC\n",
    "    output_ds[\"ML_Cp\"]=ds.ML_Cp\n",
    "    output_ds[\"ML_N\"]=ds.ML_N\n",
    "    output_ds[\"ML_S\"]=ds.ML_S\n",
    "    output_ds[\"ML_O\"]=ds.ML_O\n",
    "    #output_ds[\"NCP_positive_duration\"]=ds.NCP_positive_duration\n",
    "    \n",
    "    output_ds=output_ds.expand_dims(\"fltyear\")\n",
    "    output_df=output_ds.to_dataframe()\n",
    "    \n",
    "    All_flts_bySIB=All_flts_bySIB.append(output_df)\n",
    "    \n",
    "#define bins\n",
    "All_flts_bySIB_days=All_flts_bySIB.reset_index([\"SIB_days\"])\n",
    "groups = pd.cut(All_flts_bySIB_days[\"SIB_days\"], 30, right=True, include_lowest=True)\n",
    "\n",
    "#display bin count by group variable\n",
    "grouped_mean_SIB=All_flts_bySIB_days.groupby(groups).mean()\n",
    "grouped_std_SIB=All_flts_bySIB_days.groupby(groups).std()\n",
    "\n",
    "mpl.rcParams.update({'font.size': 18})\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "x=grouped_mean_SIB.SIB_days\n",
    "\n",
    "yC=grouped_mean_SIB.ML_Cp+grouped_std_SIB.ML_Cp\n",
    "yC2=grouped_mean_SIB.ML_Cp-grouped_std_SIB.ML_Cp\n",
    "#grouped_mean_SIB.ML_Cp.plot(ax=ax, label=\"Mixed layer Cp [mg/m3]\", color=\"blue\")\n",
    "lineC=(grouped_mean_SIB.ML_Cp)#.plot(ax=ax, label=\"Daily NCP difference\", color=\"navy\")\n",
    "ax.plot(x, lineC, color=\"blue\")\n",
    "ax.fill_between(x,yC, yC2, alpha=.15, color=\"blue\")\n",
    "\n",
    "ax1=ax.twinx()\n",
    "yN=grouped_mean_SIB.ML_N+grouped_std_SIB.ML_N\n",
    "yN2=grouped_mean_SIB.ML_N-grouped_std_SIB.ML_N\n",
    "#grouped_mean_SIB.ML_N.plot(ax=ax1, label=\"Mixed layer nitrate [umol/kg]\", color=\"red\")\n",
    "lineN=grouped_mean_SIB.ML_N\n",
    "ax1.plot(x, lineN, color=\"red\")\n",
    "ax1.fill_between(x,yN, yN2, alpha=.15, color=\"red\")\n",
    "\n",
    "ax3=ax.twinx()\n",
    "yNCP=grouped_mean_SIB.NCP_daily+grouped_std_SIB.NCP_daily\n",
    "yNCP2=grouped_mean_SIB.NCP_daily-grouped_std_SIB.NCP_daily\n",
    "#grouped_mean_SIB.NCP_daily.plot(ax=ax3, label=\"NCP [mol/m2/day]\", color=\"purple\")\n",
    "lineNCP=grouped_mean_SIB.NCP_daily\n",
    "ax3.plot(x, lineNCP*1000, color=\"purple\")\n",
    "ax3.fill_between(x,yNCP*1000, yNCP2*1000, alpha=.15, color=\"purple\")\n",
    "\n",
    "ax3.set_ylim(-5, 30)\n",
    "#ax2.set_ylim(33.7,34.5)\n",
    "ax1.set_ylim(24, 32)\n",
    "ax.set_ylim(0, 60)\n",
    "ax.set_ylabel(\"Mean mixed layer [C$_p$] (mg m$^{-3}$)\")\n",
    "ax1.set_ylabel(\"Mean mixed layer [NO$_3$$^-$] (µmol kg$^{-1}$)\")\n",
    "ax3.set_ylabel(\"Mean daily NCP (mmol C m$^{-2}$ d$^{-1}$)\")\n",
    "\n",
    "ax1.spines[\"right\"].set_position((\"axes\", 1))\n",
    "ax3.spines[\"right\"].set_position((\"axes\", 1.15))\n",
    "\n",
    "ax.spines[\"right\"].set_color(\"blue\")\n",
    "ax.yaxis.label.set_color('blue')\n",
    "ax1.spines[\"right\"].set_color(\"red\")\n",
    "ax1.yaxis.label.set_color('red')\n",
    "ax3.spines[\"right\"].set_color(\"purple\")\n",
    "ax3.yaxis.label.set_color('purple')\n",
    "ax.tick_params(axis=\"y\", colors=\"blue\")\n",
    "ax1.tick_params(axis=\"y\", colors=\"red\")\n",
    "ax3.tick_params(axis=\"y\", colors=\"purple\")\n",
    "\n",
    "ax.set_xlabel(\"Day relative to sea ice breakup\")\n",
    "\n",
    "ax.set_xlim(-20, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rSIC, p_valueSIC = stats.pearsonr(DS_Timing.SIC15_duration.values, DS_Timing.NCP.values)\n",
    "print(rSIC**2, \"rsqrd \")\n",
    "print(p_valueSIC, \"p-value NCP and SIC<15% duration\")\n",
    "\n",
    "rGP, p_valuesGP = stats.pearsonr(DS_Timing.GP.values, DS_Timing.NCP.values)\n",
    "print(rGP**2)\n",
    "print(p_valuesGP, \"p-value Ndrawdwon duration\")\n",
    "\n",
    "rml40, p_valueml40 = stats.pearsonr(DS_Timing.ML_40.values, DS_Timing.NCP.values)\n",
    "print(rml40**2)\n",
    "print(p_valueml40, \"p-value ML<40m duration\")\n",
    "\n",
    "rlght, p_valueslght = stats.pearsonr(DS_Timing.median_light_sum.values, DS_Timing.NCP.values)\n",
    "print(rlght**2)\n",
    "print(p_valueslght, \"p-value light\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_Timing[\"GP\"]=DS_Timing.GP.dt.days*-1\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4))=plt.subplots(2,2, figsize=(12,10), )\n",
    "#mpl.rcParams.update({'font.size': 15})\n",
    "#mpl.rcParams['lines.markersize'] = 22\n",
    "\n",
    "#ax1- Sum of mixed layer median light July-March\n",
    "x1 = np.linspace(DS_Timing.median_light_sum.values.min(), DS_Timing.median_light_sum.values.max(), 500)\n",
    "DS_Timing.plot.scatter(ax=ax1, x=\"median_light_sum\", y=\"NCP\", s=15)\n",
    "z1 = np.polyfit(DS_Timing.median_light_sum.values, DS_Timing.NCP.values, 1)\n",
    "p1 = np.poly1d(z1)\n",
    "R2_1 = r2_score(DS_Timing.NCP.values, p1(DS_Timing.median_light_sum.values.reshape(-1, 1)))\n",
    "#ax1.plot(x1, p1(x1.reshape(-1,1)), \"r\", label=\"r$^2$=\"+str(R2_1)[0:5])\n",
    "ax1.set_ylabel(\"bNCP (mol C m$^{-2}$ bloom$^{-1}$)\")\n",
    "ax1.set_xlabel(\"Sum of July-March mixed layer \\n median light (mol photon m$^{-2}$)\")\n",
    "\n",
    "#ax2- Days SIC<15%\n",
    "xx = np.linspace(DS_Timing.SIC15_duration.values.min(), DS_Timing.SIC15_duration.values.max(), 500)\n",
    "DS_Timing.plot.scatter(ax=ax2, x=\"SIC15_duration\", y=\"NCP\", s=15)\n",
    "z2 = np.polyfit(DS_Timing.SIC15_duration.values, DS_Timing.NCP.values, 1)\n",
    "p2 = np.poly1d(z2)\n",
    "R2_2 = r2_score(DS_Timing.NCP.values, p2(DS_Timing.SIC15_duration.values.reshape(-1, 1)))\n",
    "#ax2.plot(DS_Timing.SIC15_duration.values, p2(DS_Timing.SIC15_duration.values.reshape(-1, 1)),\"g\", alpha=.02, label=\"R$^2$=\"+str(R2_2)[0:5])\n",
    "ax2.plot(xx, p2(xx.reshape(-1, 1)),\"r\", label=\"r$^2$=\"+str(R2_2)[0:5] +\"\\n P-value=.005\")\n",
    "ax2.legend()\n",
    "ax2.set_ylabel(\"bNCP (mol C m$^{-2}$ bloom$^{-1}$)\")\n",
    "ax2.set_xlabel(\"Days with SIC < 15%\")\n",
    "\n",
    "\n",
    "#ax3 Duration N drawdown\n",
    "x3=np.linspace(DS_Timing.GP.values.min(), DS_Timing.GP.values.max(), 500)\n",
    "DS_Timing.plot.scatter(ax=ax3, x=\"GP\", y=\"NCP\",s=15)\n",
    "z3 = np.polyfit(DS_Timing.GP.values, DS_Timing.NCP.values, 1)\n",
    "p3 = np.poly1d(z3)\n",
    "R2_3 = r2_score(DS_Timing.NCP.values, p3(DS_Timing.GP.values.reshape(-1, 1)))\n",
    "#ax3.plot(DS_Timing.GP.values, p3(DS_Timing.GP.values.reshape(-1, 1)),\"r\", label=\"R$^2$=\"+str(R2_3)[0:5])\n",
    "#ax3.plot(x3, p3(x3.reshape(-1, 1)),\"r\", label=\"r$^2$=\"+str(R2_3)[0:5])\n",
    "ax3.set_ylabel(\"bNCP (mol C m$^{-2}$ bloom$^{-1}$)\")\n",
    "ax3.set_xlabel(\"Days between Min/Max Nitrate profile\")\n",
    "\n",
    "\n",
    "#ax4 - Days MLD<40m\n",
    "x4=np.linspace(DS_Timing.ML_40.values.min(), DS_Timing.ML_40.values.max(), 500)\n",
    "DS_Timing.plot.scatter(ax=ax4, x=\"ML_40\", y=\"NCP\", s=15)\n",
    "z4 = np.polyfit(DS_Timing.ML_40.values, DS_Timing.NCP.values, 1)\n",
    "p4 = np.poly1d(z4)\n",
    "R2_4 = r2_score(DS_Timing.NCP.values, p4(DS_Timing.ML_40.values.reshape(-1, 1)))\n",
    "#ax4.plot(DS_Timing.ML_40.values, p4(DS_Timing.ML_40.values.reshape(-1, 1)),\"r\", label=\"R$^2$=\"+str(R2_4)[0:5])\n",
    "#ax4.plot(x4, p4(x4.reshape(-1, 1)),\"r\", label=\"r$^2$=\"+str(R2_4)[0:5])\n",
    "ax4.set_ylabel(\"bNCP (mol C m$^{-2}$ bloom$^{-1}$)\")\n",
    "ax4.set_xlabel(\"Days with MLD < 40 m\")\n",
    "fig.tight_layout()\n",
    "\n",
    "ax1.text(-0.1, 1.1, \"a\", transform=ax1.transAxes, \n",
    "            size=20, weight='bold')\n",
    "ax2.text(-0.1, 1.1, \"b\", transform=ax2.transAxes, \n",
    "            size=20, weight='bold')\n",
    "ax3.text(-0.1, 1.1, \"c\", transform=ax3.transAxes, \n",
    "            size=20, weight='bold')\n",
    "ax4.text(-0.1, 1.1, \"d\", transform=ax4.transAxes, \n",
    "            size=20, weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1, ax2)= plt.subplots(3,1 ,figsize=(8, 20), dpi= 80)\n",
    "\n",
    "mpl.rcParams.update({'font.size': 16})\n",
    "x1 = All_sliced_50days.loc[All_sliced_50days.SIB_group=='Early SIB', 'ML_Chl']\n",
    "x2 = All_sliced_50days.loc[All_sliced_50days.SIB_group=='Late SIB', 'ML_Chl']\n",
    "\n",
    "sns.histplot(x1, stat=\"probability\", bins=40, binrange=(0, 3.7), ax=ax, label='Early sea ice breakup', linewidth=1, edgecolor=\"white\")\n",
    "sns.histplot(x2, stat=\"probability\", bins=40, binrange=(0, 3.7),ax=ax, label='Late sea ice breakup', linewidth=1, edgecolor=\"white\")\n",
    "\n",
    "ax.set_title('Probability histogram of mixed layer [Chl]\\n +/-50 days relative to total sea ice retreat')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel(\"Mixed layer [Chl] (mg m$^{-3}$)\")\n",
    "ax.legend()\n",
    "\n",
    "x1cp = All_sliced_50days.loc[All_sliced_50days.SIB_group=='Early SIB', 'ML_Cp']\n",
    "x2cp = All_sliced_50days.loc[All_sliced_50days.SIB_group=='Late SIB', 'ML_Cp']\n",
    "\n",
    "\n",
    "sns.histplot(x1cp, stat=\"probability\", ax=ax1, bins=40, binrange=(0, 180),label='Early sea ice breakup', linewidth=1, edgecolor=\"white\")\n",
    "sns.histplot(x2cp, stat=\"probability\", ax=ax1, bins=40, binrange=(0, 180),label='Late sea ice breakup', linewidth=1, edgecolor=\"white\")\n",
    "\n",
    "ax1.set_title('Probability histogram of mixed layer [C$_p$]\\n +/-50 days relative to total sea ice retreat ')\n",
    "ax1.set_ylabel('Probability')\n",
    "ax1.set_xlabel(\"Mixed layer [C$_p$] (mg m$^{-3}$)\")\n",
    "ax1.legend()\n",
    "\n",
    "x1NCP = All_slicedb4_SIB_2_SIR.loc[All_slicedb4_SIB_2_SIR.SIB_group=='Early SIB', 'NCP_daily']\n",
    "x2NCP = All_slicedb4_SIB_2_SIR.loc[All_slicedb4_SIB_2_SIR.SIB_group=='Late SIB', 'NCP_daily']\n",
    "\n",
    "sns.histplot(x1NCP*1000, stat=\"probability\", ax=ax2, bins=40, binrange=(-25, 85),label='Early sea ice breakup', linewidth=1, edgecolor=\"white\")\n",
    "sns.histplot(x2NCP*1000, stat=\"probability\", ax=ax2, bins=40, binrange=(-25, 85),label='Late sea ice breakup', linewidth=1, edgecolor=\"white\")\n",
    "\n",
    "ax2.set_title('Probability histogram of daily NCP \\n 50 days prior to total sea ice retreat ')\n",
    "ax2.set_ylabel('Probability')\n",
    "ax2.set_xlabel(\"Daily NCP (mmol C m$^{-2}$ d${-1}$)\")\n",
    "ax2.legend()\n",
    "\n",
    "ax.text(-0.1, 1.1, \"a\", transform=ax.transAxes, \n",
    "            size=20, weight='bold')\n",
    "ax2.text(-0.1, 1.1, \"c\", transform=ax2.transAxes, \n",
    "            size=20, weight='bold')\n",
    "ax1.text(-0.1, 1.1, \"b\", transform=ax1.transAxes, \n",
    "            size=20, weight='bold')\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
